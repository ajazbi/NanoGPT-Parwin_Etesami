{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7747c31e-c592-4cdc-b5ed-ab9656fe39be",
      "metadata": {
        "id": "7747c31e-c592-4cdc-b5ed-ab9656fe39be"
      },
      "source": [
        "# Small GPT, little update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f9615469-6d91-40ba-a58c-066f3c7e4097",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9615469-6d91-40ba-a58c-066f3c7e4097",
        "outputId": "bdb8a06e-21ee-4365-98d1-b4551fda13cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install transformers\n",
        "#!pip install huggingface_hub\n",
        "#!pip install transformers\n",
        "!pip install kaggle\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6fb38020-c7a1-4756-bebc-a7ca896c5677",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fb38020-c7a1-4756-bebc-a7ca896c5677",
        "outputId": "0d59d1f0-1060-4797-f213-666e8b73b5d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. GPU is ready for use.\n",
            "Device Name: NVIDIA A100-SXM4-40GB\n",
            "Number of GPUs available: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. GPU is ready for use.\")\n",
        "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
        "else:\n",
        "    print(\"CUDA is not available. Running on CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "id": "IsfL2pzPzfD9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "8b42c69b-e4a0-49ed-a448-87de8e38cc4e"
      },
      "id": "IsfL2pzPzfD9",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1462eda2-c8b3-4b72-a192-b1736fdb0ebf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1462eda2-c8b3-4b72-a192-b1736fdb0ebf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ajazbi\",\"key\":\"b05383cb636da48dedb1a00d1b53c555\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "QZ_VQ5Pd1FXH"
      },
      "id": "QZ_VQ5Pd1FXH",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n"
      ],
      "metadata": {
        "id": "GLNWDs1s1JVD"
      },
      "id": "GLNWDs1s1JVD",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7f88c813-2c60-434f-9dcf-33a704353a90",
      "metadata": {
        "id": "7f88c813-2c60-434f-9dcf-33a704353a90"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import pickle\n",
        "from contextlib import nullcontext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "from collections import Counter\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.distributed import init_process_group, destroy_process_group\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import inspect\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from transformers import AutoTokenizer\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "682b94f6-30b4-4b89-8843-4ba1423bc159",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "682b94f6-30b4-4b89-8843-4ba1423bc159",
        "outputId": "985353ae-80d0-4029-da0e-3003d8b78094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/aminghd/large-corpus-of-farsi-poems\n",
            "Total words: 70547\n",
            "Max line length: 12 words\n",
            "Total number of lines: 11144\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Authenticate with Kaggle\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Define Kaggle dataset details\n",
        "dataset = 'aminghd/large-corpus-of-farsi-poems'\n",
        "file_names = ['parvin_norm.txt']\n",
        "#file_names = ['parvin_norm.txt', 'eraghi_norm.txt', 'farrokhi_norm.txt',\n",
        "#              'helali_norm.txt', 'gilani_norm.txt', 'khosro_norm.txt'\n",
        "#              , 'salman_norm.txt', 'shahriar_norm.txt']  # Add more file names as needed\n",
        "\n",
        "# Initialize variables to store the word count, max line length, and number of lines\n",
        "total_words = 0\n",
        "max_line_length = 0\n",
        "num_lines = 0\n",
        "\n",
        "# Initialize an empty list to store the formatted lines\n",
        "formatted_lines = []\n",
        "\n",
        "for file_name in file_names:\n",
        "    # Download the specific file from the Kaggle dataset\n",
        "    api.dataset_download_file(dataset, file_name)\n",
        "\n",
        "    # Check if the file is downloaded and unzipped correctly\n",
        "    if not os.path.exists(file_name):\n",
        "        os.system(f'unzip {file_name}.zip')\n",
        "\n",
        "    # Read the content of the text file\n",
        "    with open(file_name, 'r', encoding='utf-8') as file:\n",
        "        lines = [line.strip() for line in file.readlines() if line.strip()]\n",
        "\n",
        "    # Iterate over the lines in pairs and format them with special tokens\n",
        "    for i in range(0, len(lines), 2):\n",
        "        if i + 1 < len(lines) and lines[i] and lines[i + 1]:\n",
        "            formatted_line = f\"[BOM] {lines[i]} [BOM] {lines[i+1]}[EOS]\"\n",
        "            formatted_lines.append(formatted_line)\n",
        "\n",
        "            # Update line and word counts\n",
        "            words_in_first_line = len(lines[i].split())\n",
        "            words_in_second_line = len(lines[i + 1].split())\n",
        "\n",
        "            total_words += words_in_first_line + words_in_second_line\n",
        "            max_line_length = max(max_line_length, words_in_first_line, words_in_second_line)\n",
        "            num_lines += 2  # Add 2 for each valid pair\n",
        "\n",
        "# Join the formatted lines into a single string\n",
        "sentences = \"\\n\".join(formatted_lines)\n",
        "\n",
        "# Print the entire formatted content\n",
        "# print(sentences)\n",
        "\n",
        "# Print the counts\n",
        "print(f\"Total words: {total_words}\")\n",
        "print(f\"Max line length: {max_line_length} words\")\n",
        "print(f\"Total number of lines: {num_lines}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3de8952a-3ec1-4bb7-b159-85e1ce1a6d56",
      "metadata": {
        "id": "3de8952a-3ec1-4bb7-b159-85e1ce1a6d56",
        "outputId": "b9cc196a-a7e5-45eb-ba1b-8965e905fe3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words: 9896\n"
          ]
        }
      ],
      "source": [
        "# Function to clean and count word frequencies\n",
        "def count_word_frequencies(text):\n",
        "    # Remove special tokens\n",
        "    cleaned_text = re.sub(r'\\[BOM\\]|\\[EOS\\]', '', text)\n",
        "\n",
        "    # Split text into words\n",
        "    words = cleaned_text.split()\n",
        "\n",
        "    # Count word frequencies\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    return word_counts\n",
        "\n",
        "# Count word frequencies in the formatted content\n",
        "word_frequencies = count_word_frequencies(sentences)\n",
        "\n",
        "# Get the number of unique words\n",
        "num_unique_words = len(word_frequencies)\n",
        "\n",
        "# Sort word frequencies from highest to lowest\n",
        "sorted_word_frequencies = word_frequencies.most_common()\n",
        "\n",
        "# Print the total number of unique words\n",
        "print(f'Total unique words: {num_unique_words}')\n",
        "\n",
        "# Print word frequencies from highest to lowest\n",
        "#for word, freq in sorted_word_frequencies:\n",
        "#    print(f'{word}: {freq}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e21c056f-0be4-48c5-8a54-a71d11bb32dc",
      "metadata": {
        "id": "e21c056f-0be4-48c5-8a54-a71d11bb32dc",
        "outputId": "235b3fb4-9e08-4042-8d9b-c99edd311c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "56d16ec7385d44cbbd916dd359aad478",
            "7542ccc785ea4361945dd2b2160163aa",
            "94fe15d8314d4fdeb576107a94988666",
            "ecd89974d0a5468093faadd8e5ddd927",
            "58d10890af7f4561907c67e32bf20400",
            "1f657990ba6a4097b97fc5e35b419492",
            "63617afcff8c4cca918a8f83af8c8b51",
            "fda3ba1335f04d179ba0ec2a08053b8c",
            "1dd1ecb8d2d145deb96cd628f39dc2e4",
            "5ab435adb76f4e49947744dad9e563dc",
            "25a2dffe6754497c99544d028f08ab56",
            "67d0f121b6dc4f30a01ff462e39709dc",
            "3bdf70cab4e44cc6a7af757ac64eb443",
            "b28bcd04c43f4007bd78067abc475a4e",
            "aa3a2c8c9cc8464f9cb1fef3f0157f56",
            "26da59ea42bc47dba27e235e35f6c808",
            "608b7954682447a28713acaee22d377b",
            "24abd7239b5541f98a7f82940e694794",
            "9a00eecb38c3459cbf12c48af11fa115",
            "2fd706a34a824a9b82d52e48113d6ab6",
            "a91845f6d7ef4d329077f4de96c4d9dd",
            "09b216a689784d4390174b802dcaffc3",
            "9373d88fb9c24cbb99a6f5aaec21ab08",
            "f03f1b749e94496e890ad346c1997914",
            "88d8b80d7ef44242814a2e17b310de7a",
            "9cf557e64b9c4003aa3eac3d414ba6ce",
            "431a9c80bd8d45adb208022a98aee22c",
            "1872a2c0e04249afa131a0f43bef261e",
            "a04611d925e04a85998f57675ba2e88c",
            "d015498be6d24bada6134eedac6a8f03",
            "9f744b873339439583b0fc8c94e8893d",
            "858e6fb8428846239cf819b7a49b4462",
            "ec5214000ff04809aa880d9e2506e559",
            "507d0cbb586e4da992465b61caac68d6",
            "300b84025dda475095fc90dfc4f7d5f5",
            "6d586e9e07fb49ec8ee6a602b3e2cf4a",
            "6604d2ab3779422a86749fc21849b53a",
            "503c0be0338a4adebdc241e681b18017",
            "f7d6b8706c224bbaa846aa1a7bd6bbcd",
            "8bc1b73d7bf44399a308d787e22ac67f",
            "9abc4e77cabd4fd0b7555076079bce1d",
            "38c43f8701214916a5c4a833b25cda91",
            "075f1c2b1f9b47258ad5bdc17f85fe8d",
            "cabf34c1ae12466aa46d1d9904ed0e15",
            "2d17558a52b9496184a513ff52f4b9e9",
            "7147f7f170624496ab5ebce9bb05653c",
            "d6791e267c04475d826e9f15b18db30d",
            "9c4a54279e64412da319d4f512e1b4ec",
            "6fd0c7cf17154acebd8d7667b29a320d",
            "2657bd41d839423ebdb191d34c09f970",
            "1a7ab9d3d3b54419a7fdf8c7230b88d4",
            "9f5add76e0db484c8f42767726d8c5ee",
            "22b38418fab342aca9d49ff5bae803fe",
            "b61de9594416454086b719d9d9adb1e2",
            "dfb4793d3438420ebabf782adc6d7496"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 5572\n",
            "Number of training sentences: 5014\n",
            "Number of validation sentences: 558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56d16ec7385d44cbbd916dd359aad478"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67d0f121b6dc4f30a01ff462e39709dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/537k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9373d88fb9c24cbb99a6f5aaec21ab08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.13M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "507d0cbb586e4da992465b61caac68d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d17558a52b9496184a513ff52f4b9e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data has 86,342 tokens\n",
            "Validation data has 9,548 tokens\n"
          ]
        }
      ],
      "source": [
        "sentences=formatted_lines\n",
        "# Check the number of sentences\n",
        "num_sentences = len(sentences)\n",
        "print(f\"Number of sentences: {num_sentences}\")\n",
        "\n",
        "# Ensure there are enough sentences to split\n",
        "if num_sentences > 1:\n",
        "    # Calculate the split index\n",
        "    split_index = int(num_sentences * 0.9)\n",
        "\n",
        "    # Split data into training and validation sets (90% training, 10% validation)\n",
        "    train_sentences = sentences[:split_index]\n",
        "    val_sentences = sentences[split_index:]\n",
        "\n",
        "    # Concatenate all training and validation sentences into single texts\n",
        "    train_text = ' '.join(train_sentences)\n",
        "    val_text = ' '.join(val_sentences)\n",
        "\n",
        "    print(f\"Number of training sentences: {len(train_sentences)}\")\n",
        "    print(f\"Number of validation sentences: {len(val_sentences)}\")\n",
        "else:\n",
        "    print(\"Not enough sentences to split. Please provide more data.\")\n",
        "\n",
        "# Load a Persian-specific tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "#tokenizer = AutoTokenizer.from_pretrained('HooshvareLab/gpt2-fa')\n",
        "\n",
        "# Encode the data using the Persian-specific tokenizer\n",
        "train_ids = tokenizer.encode(train_text, add_special_tokens=False)\n",
        "val_ids = tokenizer.encode(val_text, add_special_tokens=False)\n",
        "\n",
        "print(f\"Training data has {len(train_ids):,} tokens\")\n",
        "print(f\"Validation data has {len(val_ids):,} tokens\")\n",
        "\n",
        "# Convert to NumPy arrays and save to binary files  # <-- Changed to uint32\n",
        "train_ids = np.array(train_ids, dtype=np.uint32)\n",
        "val_ids = np.array(val_ids, dtype=np.uint32)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the vocabulary size\n",
        "vocab_size = tokenizer.vocab_size\n",
        "print(f\"Tokenizer vocabulary size: {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeJVWU7c2rur",
        "outputId": "1ee03c5b-a418-41ab-ff29-627b79cb6e99"
      },
      "id": "jeJVWU7c2rur",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocabulary size: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "30b1adbd-d079-4e86-a2f9-e98b0dc0ca66",
      "metadata": {
        "id": "30b1adbd-d079-4e86-a2f9-e98b0dc0ca66",
        "outputId": "2db8fb8f-12bb-4a8e-93c2-55ee714fb9a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Sample:\n",
            "[BOM] ای دل عبث مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک را و ببین آنگه[BOM] بی مهری زمانه رسوا را[EOS][BOM] این دشت خوابگاه شهیدانست[BOM] فرصت شمار وقت تماشا را[EOS][BOM] از عمر رفته نیز شماری کن\n",
            "\n",
            "Validation Data Sample:\n",
            "[BOM] من هزاران چون تو را دادم فریب[BOM] زان فریب آگه شوی عما قریب[EOS][BOM] هیچ پرسیدی که صاحبخانه کیست[BOM] هیچ گفتی در پس این پرده چیست[EOS][BOM] دیده را بستی و افتادی بچاه[BOM] ره شناسا این تو و این پرتگاه[EOS][BOM] طاس لغزنده است ای دل آز تو[BOM] مبتلایی\n"
          ]
        }
      ],
      "source": [
        "sample_size=64\n",
        "print(\"Training Data Sample:\")\n",
        "print(tokenizer.decode(train_ids[:sample_size]))\n",
        "\n",
        "print(\"\\nValidation Data Sample:\")\n",
        "print(tokenizer.decode(val_ids[:sample_size]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, block_size):\n",
        "        self.data = data\n",
        "        self.block_size = block_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Randomly sample starting index\n",
        "        start_idx = np.random.randint(0, len(self.data) - self.block_size - 1)\n",
        "        x = self.data[start_idx:start_idx + self.block_size]\n",
        "        y = self.data[start_idx + 1:start_idx + self.block_size + 1]\n",
        "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "\n",
        "def get_data_loader(data, batch_size, block_size):\n",
        "    dataset = CustomDataset(data, block_size)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "batch_size = 64\n",
        "block_size = 16\n",
        "\n",
        "# Create DataLoaders for training and validation data\n",
        "train_loader = get_data_loader(train_ids, batch_size, block_size)\n",
        "val_loader = get_data_loader(val_ids, batch_size, block_size)\n"
      ],
      "metadata": {
        "id": "gZ4ZsV56mrF3"
      },
      "id": "gZ4ZsV56mrF3",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_first_and_last_five(data_loader, tokenizer):\n",
        "    \"\"\"\n",
        "    Print the first and last five data points (x and y) from the DataLoader.\n",
        "\n",
        "    Args:\n",
        "    - data_loader (DataLoader): The DataLoader object.\n",
        "    - tokenizer (AutoTokenizer): The tokenizer for decoding.\n",
        "    \"\"\"\n",
        "    x_batch, y_batch = next(iter(data_loader))\n",
        "\n",
        "    def print_data_points(data, label):\n",
        "        batch_size = data.size(0)\n",
        "        seq_len = data.size(1)\n",
        "\n",
        "        print(f\"\\nFirst 5 sequences in {label}:\")\n",
        "        for i in range(min(5, batch_size)):\n",
        "            tokens = data[i].tolist()\n",
        "            decoded = tokenizer.decode(tokens)\n",
        "            print(f\"{label}[{i}]: Tokens: {tokens}, Decoded: {decoded}\")\n",
        "\n",
        "        print(f\"\\nLast 5 sequences in {label}:\")\n",
        "        for i in range(max(0, batch_size - 5), batch_size):\n",
        "            tokens = data[i].tolist()\n",
        "            decoded = tokenizer.decode(tokens)\n",
        "            print(f\"{label}[{i}]: Tokens: {tokens}, Decoded: {decoded}\")\n",
        "\n",
        "    print(\"First and Last 5 data points in x:\")\n",
        "    print_data_points(x_batch, 'x')\n",
        "\n",
        "    print(\"\\nFirst and Last 5 data points in y:\")\n",
        "    print_data_points(y_batch, 'y')\n",
        "\n",
        "\n",
        "# Print the first and last 5 sequences of both x and y for training and validation data\n",
        "print(\"Training Data:\")\n",
        "print_first_and_last_five(train_loader, tokenizer)\n",
        "\n",
        "print(\"\\nValidation Data:\")\n",
        "print_first_and_last_five(val_loader, tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEbBLvIuMI21",
        "outputId": "37c30dd6-125c-4065-c378-7c724524e12c"
      },
      "id": "hEbBLvIuMI21",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "First and Last 5 data points in x:\n",
            "\n",
            "First 5 sequences in x:\n",
            "x[0]: Tokens: [10366, 4702, 2227, 1768, 1967, 7, 80, 50, 24628, 6684, 105, 106, 2027, 9, 7, 161], Decoded: گذشتن ابری ضعیف تیره شوم[BOM] تو از وزیدن بادی ز کار درمانی[EOS][BOM] نه\n",
            "x[1]: Tokens: [94, 1222, 3930, 1466, 7, 5093, 50, 78, 3434, 45, 5151, 769, 9448, 43, 102, 9], Decoded: گفت زینساعت جواب[BOM] زانکه از من خیره و بیهوده بس پرسیده اند[EOS]\n",
            "x[2]: Tokens: [269, 6697, 1921, 80, 53, 906, 689, 7, 11326, 1921, 14629, 877, 436, 45, 1009, 121], Decoded: کسی جواهر تاج تو را نخواهد برد[BOM] ولیک تاج شهی گاه هست و گاهی نیست\n",
            "x[3]: Tokens: [53, 48, 7603, 9, 7, 889, 80, 91, 828, 17654, 21619, 7, 2480, 218, 17654, 6467], Decoded: را به گامی[EOS][BOM] ترا توش هنر میباید اندوخت[BOM] حدیث زندگی میباید آموخت\n",
            "x[4]: Tokens: [606, 5442, 45, 1861, 2383, 1604, 7, 121, 129, 63, 359, 43, 56, 1075, 149, 9], Decoded: صد خریدار و هزاران گنج زر[BOM] نیست چون یک دیده ی صاحب نظر[EOS]\n",
            "\n",
            "Last 5 sequences in x:\n",
            "x[59]: Tokens: [181, 157, 2057, 55, 9, 7, 7216, 3780, 1946, 987, 2404, 145, 7, 547, 18287, 237], Decoded: آبست آذر است[EOS][BOM] زاغ سپهر گوهر پاک بسی وجود[BOM] بنهفت زیر\n",
            "x[60]: Tokens: [10315, 1609, 9, 7, 5880, 80, 74, 55, 54, 248, 2644, 11326, 7, 20278, 12522, 4896], Decoded: پرگاریست[EOS][BOM] عمارت تو شد است این چنین خراب ولیک[BOM] بخانه دگران پیشه\n",
            "x[61]: Tokens: [7, 127, 5204, 10505, 1474, 106, 80, 74, 5204, 9, 7, 1520, 74, 13395, 8611, 209], Decoded: [BOM] روی درهم مکش ار کار تو شد درهم[EOS][BOM] خشک شد زمزم پاکیزه جان\n",
            "x[62]: Tokens: [9, 7, 129, 3347, 12169, 50, 4294, 45, 14857, 7, 943, 67, 53, 1282, 534, 4671], Decoded: [EOS][BOM] چون امین نشناخت از دزد و دغل[BOM] دفتر خود را نهاد اندر بغل\n",
            "x[63]: Tokens: [24356, 57, 80, 18107, 51, 4294, 80, 51, 71, 7, 111, 54, 17885, 82, 3507, 105], Decoded: خفتگان با تو نگویند که دزد تو که بود[BOM] باید این مسیله پرسید ز\n",
            "\n",
            "First and Last 5 data points in y:\n",
            "\n",
            "First 5 sequences in y:\n",
            "y[0]: Tokens: [4702, 2227, 1768, 1967, 7, 80, 50, 24628, 6684, 105, 106, 2027, 9, 7, 161, 2793], Decoded: ابری ضعیف تیره شوم[BOM] تو از وزیدن بادی ز کار درمانی[EOS][BOM] نه مقصد\n",
            "y[1]: Tokens: [1222, 3930, 1466, 7, 5093, 50, 78, 3434, 45, 5151, 769, 9448, 43, 102, 9, 7], Decoded: زینساعت جواب[BOM] زانکه از من خیره و بیهوده بس پرسیده اند[EOS][BOM]\n",
            "y[2]: Tokens: [6697, 1921, 80, 53, 906, 689, 7, 11326, 1921, 14629, 877, 436, 45, 1009, 121, 9], Decoded: جواهر تاج تو را نخواهد برد[BOM] ولیک تاج شهی گاه هست و گاهی نیست[EOS]\n",
            "y[3]: Tokens: [48, 7603, 9, 7, 889, 80, 91, 828, 17654, 21619, 7, 2480, 218, 17654, 6467, 9], Decoded: به گامی[EOS][BOM] ترا توش هنر میباید اندوخت[BOM] حدیث زندگی میباید آموخت[EOS]\n",
            "y[4]: Tokens: [5442, 45, 1861, 2383, 1604, 7, 121, 129, 63, 359, 43, 56, 1075, 149, 9, 7], Decoded: خریدار و هزاران گنج زر[BOM] نیست چون یک دیده ی صاحب نظر[EOS][BOM]\n",
            "\n",
            "Last 5 sequences in y:\n",
            "y[59]: Tokens: [157, 2057, 55, 9, 7, 7216, 3780, 1946, 987, 2404, 145, 7, 547, 18287, 237, 416], Decoded: ست آذر است[EOS][BOM] زاغ سپهر گوهر پاک بسی وجود[BOM] بنهفت زیر خاک\n",
            "y[60]: Tokens: [1609, 9, 7, 5880, 80, 74, 55, 54, 248, 2644, 11326, 7, 20278, 12522, 4896, 80], Decoded: یست[EOS][BOM] عمارت تو شد است این چنین خراب ولیک[BOM] بخانه دگران پیشه تو\n",
            "y[61]: Tokens: [127, 5204, 10505, 1474, 106, 80, 74, 5204, 9, 7, 1520, 74, 13395, 8611, 209, 7422], Decoded: روی درهم مکش ار کار تو شد درهم[EOS][BOM] خشک شد زمزم پاکیزه جان ناگه\n",
            "y[62]: Tokens: [7, 129, 3347, 12169, 50, 4294, 45, 14857, 7, 943, 67, 53, 1282, 534, 4671, 9], Decoded: [BOM] چون امین نشناخت از دزد و دغل[BOM] دفتر خود را نهاد اندر بغل[EOS]\n",
            "y[63]: Tokens: [57, 80, 18107, 51, 4294, 80, 51, 71, 7, 111, 54, 17885, 82, 3507, 105, 4441], Decoded: با تو نگویند که دزد تو که بود[BOM] باید این مسیله پرسید ز بیداری\n",
            "\n",
            "Validation Data:\n",
            "First and Last 5 data points in x:\n",
            "\n",
            "First 5 sequences in x:\n",
            "x[0]: Tokens: [2408, 45, 167, 7, 50, 1450, 45, 960, 405, 285, 121, 192, 10191, 9, 7, 5385], Decoded: رسم و راه[BOM] از رنج و سعی خویش مرا نیست هیچ عار[EOS][BOM] آسوده\n",
            "x[1]: Tokens: [78, 256, 7, 50, 235, 45, 2177, 1602, 45, 5675, 45, 9975, 9, 7, 342, 50], Decoded: منند[BOM] از گل و خار سرو و بید و چنار[EOS][BOM] وقتی از\n",
            "x[2]: Tokens: [9514, 45, 8453, 129, 5415, 3074, 9, 7, 129, 74, 56, 8783, 46, 2359, 82, 379], Decoded: موری و هوی چون مورخوار[EOS][BOM] چون شدی سرگشته در تیه نیاز\n",
            "x[3]: Tokens: [3039, 103, 5339, 7, 1376, 1779, 3293, 124, 201, 9, 7, 317, 106, 80, 129, 2557], Decoded: زند بیحد[BOM] چرخ ازین کارها کند بسیار[EOS][BOM] نقش کار تو چون نهان\n",
            "x[4]: Tokens: [14932, 56, 999, 7359, 1235, 1090, 5126, 75, 7, 10929, 91, 8963, 1400, 45, 252, 7995], Decoded: طایری کز آشیان پرواز بهر آز کرد[BOM] کیفرش فرجام بال و پر بخون\n",
            "\n",
            "Last 5 sequences in x:\n",
            "x[59]: Tokens: [246, 54, 573, 2900, 3032, 7, 2166, 359, 78, 71, 54, 23681, 56, 9, 7, 419], Decoded: چشم این ره خطا رفتم[BOM] گناه دیده من بود این خطاکاری[EOS][BOM] زن\n",
            "x[60]: Tokens: [45, 1118, 7, 80, 288, 6008, 323, 107, 14329, 9, 7, 83, 65, 668, 224, 22719], Decoded: و پست[BOM] تو چرا شوخ تن نمیشویی[EOS][BOM] همای دید سوی ماکیان\n",
            "x[61]: Tokens: [528, 3633, 107, 9218, 7, 9218, 492, 204, 317, 64, 1661, 9, 7, 78, 51, 1026], Decoded: جا دمی نمی ماندم[BOM] ماندم اکنون چو نقش بر دیوار[EOS][BOM] من که بودم\n",
            "x[62]: Tokens: [7, 15026, 45, 7004, 45, 15822, 1608, 7, 46, 446, 2042, 15158, 45, 5500, 2102, 9], Decoded: [BOM] چالاک و دلیر و کاردان باش[BOM] در وقت حصاد و خوشه چینی[EOS]\n",
            "x[63]: Tokens: [2564, 11941, 7, 51, 2171, 2496, 7858, 618, 15784, 9, 7, 54, 10693, 23602, 251, 1181], Decoded: غرق نگشت[BOM] که درین چاه ژرف پا ننهاد[EOS][BOM] این معما بفکر گفته نشد\n",
            "\n",
            "First and Last 5 data points in y:\n",
            "\n",
            "First 5 sequences in y:\n",
            "y[0]: Tokens: [45, 167, 7, 50, 1450, 45, 960, 405, 285, 121, 192, 10191, 9, 7, 5385, 605], Decoded: و راه[BOM] از رنج و سعی خویش مرا نیست هیچ عار[EOS][BOM] آسوده آنکه\n",
            "y[1]: Tokens: [256, 7, 50, 235, 45, 2177, 1602, 45, 5675, 45, 9975, 9, 7, 342, 50, 106], Decoded: ند[BOM] از گل و خار سرو و بید و چنار[EOS][BOM] وقتی از کار\n",
            "y[2]: Tokens: [45, 8453, 129, 5415, 3074, 9, 7, 129, 74, 56, 8783, 46, 2359, 82, 379, 7], Decoded: و هوی چون مورخوار[EOS][BOM] چون شدی سرگشته در تیه نیاز[BOM]\n",
            "y[3]: Tokens: [103, 5339, 7, 1376, 1779, 3293, 124, 201, 9, 7, 317, 106, 80, 129, 2557, 1260], Decoded: بیحد[BOM] چرخ ازین کارها کند بسیار[EOS][BOM] نقش کار تو چون نهان ماند\n",
            "y[4]: Tokens: [56, 999, 7359, 1235, 1090, 5126, 75, 7, 10929, 91, 8963, 1400, 45, 252, 7995, 5509], Decoded: ی کز آشیان پرواز بهر آز کرد[BOM] کیفرش فرجام بال و پر بخون آلود\n",
            "\n",
            "Last 5 sequences in y:\n",
            "y[59]: Tokens: [54, 573, 2900, 3032, 7, 2166, 359, 78, 71, 54, 23681, 56, 9, 7, 419, 46], Decoded: این ره خطا رفتم[BOM] گناه دیده من بود این خطاکاری[EOS][BOM] زن در\n",
            "y[60]: Tokens: [1118, 7, 80, 288, 6008, 323, 107, 14329, 9, 7, 83, 65, 668, 224, 22719, 244], Decoded: پست[BOM] تو چرا شوخ تن نمیشویی[EOS][BOM] همای دید سوی ماکیان ب\n",
            "y[61]: Tokens: [3633, 107, 9218, 7, 9218, 492, 204, 317, 64, 1661, 9, 7, 78, 51, 1026, 2283], Decoded: دمی نمی ماندم[BOM] ماندم اکنون چو نقش بر دیوار[EOS][BOM] من که بودم پزشک\n",
            "y[62]: Tokens: [15026, 45, 7004, 45, 15822, 1608, 7, 46, 446, 2042, 15158, 45, 5500, 2102, 9, 7], Decoded: چالاک و دلیر و کاردان باش[BOM] در وقت حصاد و خوشه چینی[EOS][BOM]\n",
            "y[63]: Tokens: [11941, 7, 51, 2171, 2496, 7858, 618, 15784, 9, 7, 54, 10693, 23602, 251, 1181, 7], Decoded: نگشت[BOM] که درین چاه ژرف پا ننهاد[EOS][BOM] این معما بفکر گفته نشد[BOM]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "572ed86e-ac81-4a4e-8f1d-1a18202d05a6",
      "metadata": {
        "id": "572ed86e-ac81-4a4e-8f1d-1a18202d05a6"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset class\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, data, block_size):\n",
        "        self.data = data\n",
        "        self.block_size = block_size\n",
        "        # Ensure the data is a torch tensor\n",
        "        if not isinstance(self.data, torch.Tensor):\n",
        "            self.data = torch.tensor(self.data, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size - 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self):\n",
        "            raise IndexError(\"Index out of range\")\n",
        "        x = self.data[idx:idx + self.block_size]\n",
        "        y = self.data[idx + 1:idx + 1 + self.block_size]\n",
        "        return x, y\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
        "\n",
        "    def __init__(self, ndim, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        # regularization\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.dropout = config.dropout\n",
        "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
        "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
        "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                        .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        if self.flash:\n",
        "            # efficient attention using Flash Attention CUDA kernels\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
        "        else:\n",
        "            # manual implementation of attention\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.gelu    = nn.GELU()\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight  # Weight tying\n",
        "\n",
        "        # Init all weights\n",
        "        self.apply(self._init_weights)\n",
        "        # Apply special scaled init to the residual projections, per GPT-2 paper\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        # Report number of parameters\n",
        "        print(\"number of parameters: %.2fM\" % (self.get_num_params() / 1e6,))\n",
        "\n",
        "    def get_num_params(self, non_embedding=True):\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        if non_embedding:\n",
        "            n_params -= self.transformer.wpe.weight.numel()\n",
        "        return n_params\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device)  # shape (t)\n",
        "\n",
        "        # Forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx)  # token embeddings of shape (b, t, n_embd)\n",
        "        pos_emb = self.transformer.wpe(pos)  # position embeddings of shape (t, n_embd)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            # If we are given some desired targets also calculate the loss\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "        else:\n",
        "            # Inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "            logits = self.lm_head(x[:, [-1], :])  # note: using list [-1] to preserve the time dim\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
        "        # start with all of the candidate parameters\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        # filter out those that do not require grad\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {'params': decay_params, 'weight_decay': weight_decay},\n",
        "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "        # Create AdamW optimizer and use the fused version if it is available\n",
        "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "        use_fused = fused_available and device_type == 'cuda'\n",
        "        extra_args = dict(fused=True) if use_fused else dict()\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
        "        print(f\"using fused AdamW: {use_fused}\")\n",
        "\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "484985e9-f86f-4f5f-8d45-717d6b54c1a2",
      "metadata": {
        "id": "484985e9-f86f-4f5f-8d45-717d6b54c1a2",
        "outputId": "68dcfe6c-ee97-4740-a110-84c7c64902c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 7.98M\n",
            "GPT(\n",
            "  (transformer): ModuleDict(\n",
            "    (wte): Embedding(25000, 256)\n",
            "    (wpe): Embedding(16, 256)\n",
            "    (drop): Dropout(p=0, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-1): 2 x Block(\n",
            "        (ln_1): LayerNorm()\n",
            "        (attn): CausalSelfAttention(\n",
            "          (c_attn): Linear(in_features=256, out_features=768, bias=True)\n",
            "          (c_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (attn_dropout): Dropout(p=0, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm()\n",
            "        (mlp): MLP(\n",
            "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (gelu): GELU(approximate='none')\n",
            "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (dropout): Dropout(p=0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=256, out_features=25000, bias=False)\n",
            ")\n",
            "vocab_size= 25000\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int\n",
        "    vocab_size: int\n",
        "    n_layer: int\n",
        "    n_head: int\n",
        "    n_embd: int  # n_embd must be divisible by n_head\n",
        "    dropout: float\n",
        "    bias: bool\n",
        "\"\"\"\n",
        "config = GPTConfig(\n",
        "    block_size=64,\n",
        "    vocab_size= vocab_size,\n",
        "    n_layer=4,\n",
        "    n_head=4,\n",
        "    n_embd=64,  # Ensure n_embd is divisible by n_head\n",
        "    dropout=0.1,\n",
        "    bias=True\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "config = GPTConfig(\n",
        "    block_size=block_size,\n",
        "    vocab_size= vocab_size,\n",
        "    n_layer=2,\n",
        "    n_head=2,\n",
        "    n_embd=256,  # Ensure n_embd is divisible by n_head\n",
        "    dropout=0,\n",
        "    bias=True\n",
        ")\n",
        "\n",
        "\n",
        "model = GPT(config)\n",
        "print(model)\n",
        "\n",
        "print (\"vocab_size=\" , vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "84823ac5-2153-4215-a016-1c6d6200e9b0",
      "metadata": {
        "id": "84823ac5-2153-4215-a016-1c6d6200e9b0",
        "outputId": "a0155d0f-5ba0-4c5f-8c76-6ab95c52bc5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num decayed parameter tensors: 10, with 7,976,960 parameters\n",
            "num non-decayed parameter tensors: 18, with 7,168 parameters\n",
            "using fused AdamW: True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize optimizer\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)  # Ensure the model is on the correct device\n",
        "optimizer = model.configure_optimizers(weight_decay=0.1, learning_rate=3e-4, betas=(0.9, 0.95), device_type=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "9d4f1dba-5738-4bad-9cc4-ca6ff0cb62f9",
      "metadata": {
        "id": "9d4f1dba-5738-4bad-9cc4-ca6ff0cb62f9"
      },
      "outputs": [],
      "source": [
        "# Define the learning rate scheduler\n",
        "def get_lr(it):\n",
        "    # 1) Linear warmup for warmup_iters steps\n",
        "    if it < warmup_iters:\n",
        "        return learning_rate * it / warmup_iters\n",
        "    # 2) If it > lr_decay_iters, return min learning rate\n",
        "    if it > lr_decay_iters:\n",
        "        return min_lr\n",
        "    # 3) In between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))  # coeff ranges 0..1\n",
        "    return min_lr + coeff * (learning_rate - min_lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define global configurations and hyperparameters\n",
        "\n",
        "config = {\n",
        "    'learning_rate': 3e-4,\n",
        "    'always_save_checkpoint': True,\n",
        "    'out_dir': './checkpoints',\n",
        "    'eval_only': False,\n",
        "    'gradient_accumulation_steps': 4,\n",
        "    'eval_interval': 20,\n",
        "    'max_iters': 2000,\n",
        "    'log_interval': 10,\n",
        "    'grad_clip': 0.1,\n",
        "    'decay_lr': False,\n",
        "    'max_epochs': 50,\n",
        "    'target_val_loss': 2  # Example target validation loss\n",
        "}\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Disable scaler and autocast if CUDA is not available\n",
        "use_amp = torch.cuda.is_available()\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "iter_num = 0\n",
        "best_val_loss = float('inf')\n",
        "epoch = 0\n",
        "\n",
        "while epoch < config['max_epochs']:\n",
        "    train_loader = get_data_loader(train_ids, batch_size, block_size)\n",
        "    val_loader = get_data_loader(val_ids, batch_size, block_size)\n",
        "\n",
        "    for batch_idx, (X, Y) in enumerate(train_loader):\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "\n",
        "        # Determine and set the learning rate for this iteration\n",
        "        lr = get_lr(iter_num) if config['decay_lr'] else config['learning_rate']\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        # Forward, backward update with gradient accumulation\n",
        "        for micro_step in range(config['gradient_accumulation_steps']):\n",
        "            logits, loss = model(X, Y)\n",
        "            loss = loss / config['gradient_accumulation_steps']  # scale the loss to account for gradient accumulation\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "        # Clip the gradient\n",
        "        if config['grad_clip'] != 0.0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['grad_clip'])\n",
        "        # Step the optimizer and scaler\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        iter_num += 1\n",
        "\n",
        "        # Print loss every 10 iterations\n",
        "        if iter_num % 10 == 0:\n",
        "            print(f\"Iteration {iter_num}, Loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "        # Evaluate the loss on train/val sets and write checkpoints\n",
        "        if iter_num % config['eval_interval'] == 0:\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for val_X, val_Y in val_loader:\n",
        "                    val_X, val_Y = val_X.to(device), val_Y.to(device)\n",
        "                    logits, loss = model(val_X, val_Y)\n",
        "                    val_loss += loss.item()\n",
        "            val_loss /= len(val_loader)\n",
        "            model.train()\n",
        "\n",
        "            print(f\"step {iter_num}: val loss {val_loss:.4f}\")\n",
        "            if val_loss < best_val_loss or config['always_save_checkpoint']:\n",
        "                best_val_loss = val_loss\n",
        "                if iter_num > 0:\n",
        "                    checkpoint = {\n",
        "                        'model': model.state_dict(),\n",
        "                        'optimizer': optimizer.state_dict(),\n",
        "                        'config': config,\n",
        "                        'iter_num': iter_num,\n",
        "                        'best_val_loss': best_val_loss,\n",
        "                    }\n",
        "                    #print(f\"saving checkpoint to {config['out_dir']}\")\n",
        "                    #torch.save(checkpoint, os.path.join(config['out_dir'], 'ckpt.pt'))\n",
        "            if val_loss < config['target_val_loss']:\n",
        "                print(\"Target validation loss achieved. Stopping training.\")\n",
        "                break\n",
        "\n",
        "        # Termination condition\n",
        "        if iter_num >= config['max_iters']:\n",
        "            break\n",
        "\n",
        "    epoch += 1\n",
        "    if iter_num >= config['max_iters']:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFMlzfTEi8Am",
        "outputId": "519abd13-66f0-406e-f4ef-b4bb872871ab"
      },
      "id": "jFMlzfTEi8Am",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10, Loss: 1.4306659698486328\n",
            "Iteration 20, Loss: 1.4253414869308472\n",
            "step 20: val loss 6.0358\n",
            "Iteration 30, Loss: 1.4341115951538086\n",
            "Iteration 40, Loss: 1.4586836099624634\n",
            "step 40: val loss 6.0316\n",
            "Iteration 50, Loss: 1.459630012512207\n",
            "Iteration 60, Loss: 1.412857174873352\n",
            "step 60: val loss 6.0153\n",
            "Iteration 70, Loss: 1.4063925743103027\n",
            "Iteration 80, Loss: 1.369399070739746\n",
            "step 80: val loss 6.0025\n",
            "Iteration 90, Loss: 1.4262962341308594\n",
            "Iteration 100, Loss: 1.4046907424926758\n",
            "step 100: val loss 5.9798\n",
            "Iteration 110, Loss: 1.3977774381637573\n",
            "Iteration 120, Loss: 1.3722538948059082\n",
            "step 120: val loss 5.9969\n",
            "Iteration 130, Loss: 1.400181770324707\n",
            "Iteration 140, Loss: 1.3673624992370605\n",
            "step 140: val loss 6.0013\n",
            "Iteration 150, Loss: 1.3681200742721558\n",
            "Iteration 160, Loss: 1.3567216396331787\n",
            "step 160: val loss 5.9864\n",
            "Iteration 170, Loss: 1.3671324253082275\n",
            "Iteration 180, Loss: 1.3537708520889282\n",
            "step 180: val loss 5.9800\n",
            "Iteration 190, Loss: 1.373766303062439\n",
            "Iteration 200, Loss: 1.338445782661438\n",
            "step 200: val loss 5.9658\n",
            "Iteration 210, Loss: 1.3326139450073242\n",
            "Iteration 220, Loss: 1.3503427505493164\n",
            "step 220: val loss 5.9994\n",
            "Iteration 230, Loss: 1.3252357244491577\n",
            "Iteration 240, Loss: 1.3268966674804688\n",
            "step 240: val loss 5.9710\n",
            "Iteration 250, Loss: 1.3086750507354736\n",
            "Iteration 260, Loss: 1.3260233402252197\n",
            "step 260: val loss 5.9919\n",
            "Iteration 270, Loss: 1.335034728050232\n",
            "Iteration 280, Loss: 1.3006761074066162\n",
            "step 280: val loss 5.9707\n",
            "Iteration 290, Loss: 1.3089494705200195\n",
            "Iteration 300, Loss: 1.3076581954956055\n",
            "step 300: val loss 5.9742\n",
            "Iteration 310, Loss: 1.3244301080703735\n",
            "Iteration 320, Loss: 1.3054684400558472\n",
            "step 320: val loss 5.9812\n",
            "Iteration 330, Loss: 1.3057523965835571\n",
            "Iteration 340, Loss: 1.301165223121643\n",
            "step 340: val loss 5.9758\n",
            "Iteration 350, Loss: 1.3084791898727417\n",
            "Iteration 360, Loss: 1.2725375890731812\n",
            "step 360: val loss 5.9660\n",
            "Iteration 370, Loss: 1.2721362113952637\n",
            "Iteration 380, Loss: 1.280077576637268\n",
            "step 380: val loss 5.9742\n",
            "Iteration 390, Loss: 1.286481499671936\n",
            "Iteration 400, Loss: 1.2599103450775146\n",
            "step 400: val loss 5.9671\n",
            "Iteration 410, Loss: 1.272055745124817\n",
            "Iteration 420, Loss: 1.2410372495651245\n",
            "step 420: val loss 5.9782\n",
            "Iteration 430, Loss: 1.2536224126815796\n",
            "Iteration 440, Loss: 1.244839072227478\n",
            "step 440: val loss 5.9890\n",
            "Iteration 450, Loss: 1.2616443634033203\n",
            "Iteration 460, Loss: 1.2431288957595825\n",
            "step 460: val loss 5.9904\n",
            "Iteration 470, Loss: 1.2600493431091309\n",
            "Iteration 480, Loss: 1.2285772562026978\n",
            "step 480: val loss 5.9781\n",
            "Iteration 490, Loss: 1.219138741493225\n",
            "Iteration 500, Loss: 1.2295957803726196\n",
            "step 500: val loss 5.9738\n",
            "Iteration 510, Loss: 1.2253479957580566\n",
            "Iteration 520, Loss: 1.2038155794143677\n",
            "step 520: val loss 5.9851\n",
            "Iteration 530, Loss: 1.2432713508605957\n",
            "Iteration 540, Loss: 1.220841884613037\n",
            "step 540: val loss 5.9791\n",
            "Iteration 550, Loss: 1.2390283346176147\n",
            "Iteration 560, Loss: 1.1954416036605835\n",
            "step 560: val loss 5.9971\n",
            "Iteration 570, Loss: 1.2306551933288574\n",
            "Iteration 580, Loss: 1.2267223596572876\n",
            "step 580: val loss 5.9914\n",
            "Iteration 590, Loss: 1.2179468870162964\n",
            "Iteration 600, Loss: 1.202930212020874\n",
            "step 600: val loss 5.9813\n",
            "Iteration 610, Loss: 1.2211315631866455\n",
            "Iteration 620, Loss: 1.1744532585144043\n",
            "step 620: val loss 5.9907\n",
            "Iteration 630, Loss: 1.2081209421157837\n",
            "Iteration 640, Loss: 1.1862057447433472\n",
            "step 640: val loss 6.0019\n",
            "Iteration 650, Loss: 1.1855242252349854\n",
            "Iteration 660, Loss: 1.1582647562026978\n",
            "step 660: val loss 6.0184\n",
            "Iteration 670, Loss: 1.190500259399414\n",
            "Iteration 680, Loss: 1.1791552305221558\n",
            "step 680: val loss 6.0302\n",
            "Iteration 690, Loss: 1.1812955141067505\n",
            "Iteration 700, Loss: 1.1723753213882446\n",
            "step 700: val loss 6.0324\n",
            "Iteration 710, Loss: 1.1604907512664795\n",
            "Iteration 720, Loss: 1.1867053508758545\n",
            "step 720: val loss 6.0191\n",
            "Iteration 730, Loss: 1.1518850326538086\n",
            "Iteration 740, Loss: 1.1319563388824463\n",
            "step 740: val loss 6.0351\n",
            "Iteration 750, Loss: 1.1460976600646973\n",
            "Iteration 760, Loss: 1.1480380296707153\n",
            "step 760: val loss 6.0768\n",
            "Iteration 770, Loss: 1.162082314491272\n",
            "Iteration 780, Loss: 1.1117489337921143\n",
            "step 780: val loss 6.0595\n",
            "Iteration 790, Loss: 1.151397943496704\n",
            "Iteration 800, Loss: 1.1572566032409668\n",
            "step 800: val loss 6.0328\n",
            "Iteration 810, Loss: 1.148107647895813\n",
            "Iteration 820, Loss: 1.112585425376892\n",
            "step 820: val loss 6.0696\n",
            "Iteration 830, Loss: 1.1469862461090088\n",
            "Iteration 840, Loss: 1.1163681745529175\n",
            "step 840: val loss 6.0819\n",
            "Iteration 850, Loss: 1.0933531522750854\n",
            "Iteration 860, Loss: 1.1448832750320435\n",
            "step 860: val loss 6.0799\n",
            "Iteration 870, Loss: 1.101731300354004\n",
            "Iteration 880, Loss: 1.1030662059783936\n",
            "step 880: val loss 6.0814\n",
            "Iteration 890, Loss: 1.106583595275879\n",
            "Iteration 900, Loss: 1.1210790872573853\n",
            "step 900: val loss 6.0927\n",
            "Iteration 910, Loss: 1.0873401165008545\n",
            "Iteration 920, Loss: 1.091552734375\n",
            "step 920: val loss 6.1316\n",
            "Iteration 930, Loss: 1.0826255083084106\n",
            "Iteration 940, Loss: 1.0864853858947754\n",
            "step 940: val loss 6.1104\n",
            "Iteration 950, Loss: 1.1010406017303467\n",
            "Iteration 960, Loss: 1.11015784740448\n",
            "step 960: val loss 6.1363\n",
            "Iteration 970, Loss: 1.0752543210983276\n",
            "Iteration 980, Loss: 1.0787744522094727\n",
            "step 980: val loss 6.1625\n",
            "Iteration 990, Loss: 1.0709426403045654\n",
            "Iteration 1000, Loss: 1.0563489198684692\n",
            "step 1000: val loss 6.1494\n",
            "Iteration 1010, Loss: 1.0640043020248413\n",
            "Iteration 1020, Loss: 1.0397700071334839\n",
            "step 1020: val loss 6.1605\n",
            "Iteration 1030, Loss: 1.093702793121338\n",
            "Iteration 1040, Loss: 1.062647819519043\n",
            "step 1040: val loss 6.1795\n",
            "Iteration 1050, Loss: 1.0250393152236938\n",
            "Iteration 1060, Loss: 1.0295042991638184\n",
            "step 1060: val loss 6.1803\n",
            "Iteration 1070, Loss: 1.054450511932373\n",
            "Iteration 1080, Loss: 1.0540763139724731\n",
            "step 1080: val loss 6.2045\n",
            "Iteration 1090, Loss: 1.0446211099624634\n",
            "Iteration 1100, Loss: 1.0137417316436768\n",
            "step 1100: val loss 6.2184\n",
            "Iteration 1110, Loss: 1.024071455001831\n",
            "Iteration 1120, Loss: 1.017316460609436\n",
            "step 1120: val loss 6.2273\n",
            "Iteration 1130, Loss: 1.0423779487609863\n",
            "Iteration 1140, Loss: 0.9982017278671265\n",
            "step 1140: val loss 6.2104\n",
            "Iteration 1150, Loss: 1.0547398328781128\n",
            "Iteration 1160, Loss: 0.9878444671630859\n",
            "step 1160: val loss 6.2115\n",
            "Iteration 1170, Loss: 0.9823440313339233\n",
            "Iteration 1180, Loss: 1.0190315246582031\n",
            "step 1180: val loss 6.2452\n",
            "Iteration 1190, Loss: 0.9879546165466309\n",
            "Iteration 1200, Loss: 0.9971837997436523\n",
            "step 1200: val loss 6.2700\n",
            "Iteration 1210, Loss: 1.0117385387420654\n",
            "Iteration 1220, Loss: 0.9683077335357666\n",
            "step 1220: val loss 6.2872\n",
            "Iteration 1230, Loss: 0.953187882900238\n",
            "Iteration 1240, Loss: 0.9489746689796448\n",
            "step 1240: val loss 6.2828\n",
            "Iteration 1250, Loss: 1.0079717636108398\n",
            "Iteration 1260, Loss: 0.9700855016708374\n",
            "step 1260: val loss 6.2801\n",
            "Iteration 1270, Loss: 0.9610816836357117\n",
            "Iteration 1280, Loss: 0.9580917954444885\n",
            "step 1280: val loss 6.3374\n",
            "Iteration 1290, Loss: 0.9705040454864502\n",
            "Iteration 1300, Loss: 0.9837858080863953\n",
            "step 1300: val loss 6.3211\n",
            "Iteration 1310, Loss: 0.9625893831253052\n",
            "Iteration 1320, Loss: 0.9782288670539856\n",
            "step 1320: val loss 6.3101\n",
            "Iteration 1330, Loss: 0.9461137056350708\n",
            "Iteration 1340, Loss: 0.9504809379577637\n",
            "step 1340: val loss 6.3181\n",
            "Iteration 1350, Loss: 0.9617127776145935\n",
            "Iteration 1360, Loss: 0.9646720886230469\n",
            "step 1360: val loss 6.3475\n",
            "Iteration 1370, Loss: 0.9209412932395935\n",
            "Iteration 1380, Loss: 0.9354043006896973\n",
            "step 1380: val loss 6.3604\n",
            "Iteration 1390, Loss: 0.9615043997764587\n",
            "Iteration 1400, Loss: 0.9158898591995239\n",
            "step 1400: val loss 6.3695\n",
            "Iteration 1410, Loss: 0.9656780362129211\n",
            "Iteration 1420, Loss: 0.9391122460365295\n",
            "step 1420: val loss 6.3965\n",
            "Iteration 1430, Loss: 0.9220064282417297\n",
            "Iteration 1440, Loss: 0.9164420962333679\n",
            "step 1440: val loss 6.3839\n",
            "Iteration 1450, Loss: 0.9496092200279236\n",
            "Iteration 1460, Loss: 0.8947689533233643\n",
            "step 1460: val loss 6.4485\n",
            "Iteration 1470, Loss: 0.930077075958252\n",
            "Iteration 1480, Loss: 0.9038854241371155\n",
            "step 1480: val loss 6.4271\n",
            "Iteration 1490, Loss: 0.8734769225120544\n",
            "Iteration 1500, Loss: 0.8739776015281677\n",
            "step 1500: val loss 6.4253\n",
            "Iteration 1510, Loss: 0.8817639350891113\n",
            "Iteration 1520, Loss: 0.8849725723266602\n",
            "step 1520: val loss 6.4819\n",
            "Iteration 1530, Loss: 0.8845226168632507\n",
            "Iteration 1540, Loss: 0.8931792974472046\n",
            "step 1540: val loss 6.4642\n",
            "Iteration 1550, Loss: 0.9148069620132446\n",
            "Iteration 1560, Loss: 0.8836816549301147\n",
            "step 1560: val loss 6.4805\n",
            "Iteration 1570, Loss: 0.8589121699333191\n",
            "Iteration 1580, Loss: 0.8751513957977295\n",
            "step 1580: val loss 6.4917\n",
            "Iteration 1590, Loss: 0.8801261186599731\n",
            "Iteration 1600, Loss: 0.8759180307388306\n",
            "step 1600: val loss 6.5443\n",
            "Iteration 1610, Loss: 0.8940752744674683\n",
            "Iteration 1620, Loss: 0.8971894383430481\n",
            "step 1620: val loss 6.5391\n",
            "Iteration 1630, Loss: 0.8564119338989258\n",
            "Iteration 1640, Loss: 0.8658691048622131\n",
            "step 1640: val loss 6.5587\n",
            "Iteration 1650, Loss: 0.8487785458564758\n",
            "Iteration 1660, Loss: 0.8064308762550354\n",
            "step 1660: val loss 6.5527\n",
            "Iteration 1670, Loss: 0.8217848539352417\n",
            "Iteration 1680, Loss: 0.8251824378967285\n",
            "step 1680: val loss 6.5969\n",
            "Iteration 1690, Loss: 0.839093804359436\n",
            "Iteration 1700, Loss: 0.8021029233932495\n",
            "step 1700: val loss 6.5936\n",
            "Iteration 1710, Loss: 0.8160629272460938\n",
            "Iteration 1720, Loss: 0.8285484313964844\n",
            "step 1720: val loss 6.5983\n",
            "Iteration 1730, Loss: 0.8164359331130981\n",
            "Iteration 1740, Loss: 0.8456849455833435\n",
            "step 1740: val loss 6.6213\n",
            "Iteration 1750, Loss: 0.7718372344970703\n",
            "Iteration 1760, Loss: 0.8499216437339783\n",
            "step 1760: val loss 6.6363\n",
            "Iteration 1770, Loss: 0.8299504518508911\n",
            "Iteration 1780, Loss: 0.8326557874679565\n",
            "step 1780: val loss 6.6897\n",
            "Iteration 1790, Loss: 0.7885380387306213\n",
            "Iteration 1800, Loss: 0.8104338645935059\n",
            "step 1800: val loss 6.6589\n",
            "Iteration 1810, Loss: 0.7767603397369385\n",
            "Iteration 1820, Loss: 0.8197526931762695\n",
            "step 1820: val loss 6.6912\n",
            "Iteration 1830, Loss: 0.7756565809249878\n",
            "Iteration 1840, Loss: 0.8051822781562805\n",
            "step 1840: val loss 6.7081\n",
            "Iteration 1850, Loss: 0.8014260530471802\n",
            "Iteration 1860, Loss: 0.776865541934967\n",
            "step 1860: val loss 6.7153\n",
            "Iteration 1870, Loss: 0.7767544984817505\n",
            "Iteration 1880, Loss: 0.7238382697105408\n",
            "step 1880: val loss 6.7378\n",
            "Iteration 1890, Loss: 0.7631248235702515\n",
            "Iteration 1900, Loss: 0.7632623314857483\n",
            "step 1900: val loss 6.7378\n",
            "Iteration 1910, Loss: 0.7561203837394714\n",
            "Iteration 1920, Loss: 0.7275991439819336\n",
            "step 1920: val loss 6.7879\n",
            "Iteration 1930, Loss: 0.7454848289489746\n",
            "Iteration 1940, Loss: 0.7476383447647095\n",
            "step 1940: val loss 6.7767\n",
            "Iteration 1950, Loss: 0.7688139081001282\n",
            "Iteration 1960, Loss: 0.7088161110877991\n",
            "step 1960: val loss 6.7512\n",
            "Iteration 1970, Loss: 0.7636891007423401\n",
            "Iteration 1980, Loss: 0.7480905652046204\n",
            "step 1980: val loss 6.8286\n",
            "Iteration 1990, Loss: 0.7208210825920105\n",
            "Iteration 2000, Loss: 0.747889518737793\n",
            "step 2000: val loss 6.8072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "69850b19-4e6f-4fe3-908b-4dd315062099",
      "metadata": {
        "id": "69850b19-4e6f-4fe3-908b-4dd315062099",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7c0e1d-58a9-4801-dc16-00aa81cd475c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and optimizer state saved to GPTper_saves\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model, optimizer state, and configuration details\n",
        "save_dir = 'GPTper_saves'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "torch.save(model.state_dict(), os.path.join(save_dir, 'final_model_perchin.pt'))\n",
        "torch.save(optimizer.state_dict(), os.path.join(save_dir, 'final_optimizer_perchin.pt'))\n",
        "\n",
        "print(f'Model and optimizer state saved to {save_dir}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "662dfe7d-0d0a-4e1a-9aba-4ca88d848519",
      "metadata": {
        "id": "662dfe7d-0d0a-4e1a-9aba-4ca88d848519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eca40a0-b701-4ba0-c8b5-f400d2b6b88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Text:\n",
            "تو خوشگل ناز منی  است [EOS] [BOM]\n",
            " ترا در آتش آمد مرا آب [BOM]\n",
            " ترا در هر چه کرد ره و رسم دگر بار [EOS] [BOM]\n",
            " درین باغ چون خرمن کردم هزار [BOM]\n",
            " تا لاف   اند تا هنر اند به جز یک خم نیست [EOS] [BOM]\n",
            " در یک نفس با خود می بری یم ولیک [BOM]\n",
            " ترا بر با دست و و در م خراش ید [EOS] [BOM]\n",
            " هزار مرتبه ای از دست ز دست [BOM]\n",
            " پای در راه دل به جز خار نداشت [EOS] [BOM]\n",
            " در راه کج علم و هنر و علم در راه کج [BOM]\n",
            " بهر خود باش این درد و نابود ه این نام را [EOS] [BOM]\n",
            " از چه معنی کار هاست لانه را [BOM]\n",
            " بی خبر ان کشت ما را [EOS] [BOM]\n",
            " ما را نمی آید م پوی ه باز اند ن رنج ها [EOS] [BOM]\n",
            " آخر آن بزم ت را می دید [BOM]\n",
            " تا  زین ره و رسم از ما دوست       خواهد کرد [EOS] [BOM]\n",
            " ز ات ش از آفتاب نگاه [BOM]\n",
            " گفت چون روز مرا یک لحظه بینی [EOS] [BOM]\n",
            " من که شب این گلشن نه [BOM]\n",
            " مرا در خانه دل پاک بود ای رنجبر [EOS] [BOM]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Function to tokenize input text and truncate to block size\n",
        "def tokenize_and_truncate_text(text, block_size):\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
        "    if len(tokens) > block_size:\n",
        "        tokens = tokens[-block_size:]  # Truncate to the last block_size tokens\n",
        "    return torch.tensor(tokens, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Function to decode output tokens\n",
        "def decode_output(predicted_ids):\n",
        "    predicted_tokens = predicted_ids.tolist()  # Convert tensor to list\n",
        "    predicted_text = tokenizer.decode(predicted_tokens)\n",
        "    return predicted_text\n",
        "\n",
        "# Function to get model output for a single input text\n",
        "def get_model_output(model, input_text, config, temperature=1.0, top_k=50):\n",
        "    model.eval()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Tokenize and truncate input text\n",
        "    input_ids = tokenize_and_truncate_text(input_text, block_size)\n",
        "    input_ids = input_ids.to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits, _ = model(input_ids)\n",
        "        logits = logits[:, -1, :] / temperature  # Apply temperature\n",
        "\n",
        "        # Top-k sampling\n",
        "        top_k_logits, top_k_indices = torch.topk(logits, k=top_k, dim=-1)\n",
        "        probs = F.softmax(top_k_logits, dim=-1)\n",
        "\n",
        "        # Sample from the distribution\n",
        "        chosen_idx = torch.multinomial(probs, num_samples=1)\n",
        "        predicted_token_id = top_k_indices[0, chosen_idx[0]]\n",
        "\n",
        "        # Decode the predicted token\n",
        "        predicted_text = decode_output(predicted_token_id)\n",
        "\n",
        "    return predicted_text\n",
        "\n",
        "# Function to validate the predicted text\n",
        "def is_valid_token(token):\n",
        "    # Implement your logic to check if the token is valid or not\n",
        "    # This can include checking for known invalid sequences, punctuation, etc.\n",
        "    invalid_sequences = ['ا ی']\n",
        "    return token not in invalid_sequences\n",
        "\n",
        "# Sample input text\n",
        "input_text = \"بنشین که با من هر نظر\"\n",
        "input_text = \"دست هر کودک ده ساله شهر\"\n",
        "input_text = \"تو خوشگل ناز منی \"\n",
        "input_text = \"دور است کاروان سحر\"\n",
        "input_text = \"حکیمان پیشین چنین گفته اند\"\n",
        "input_text = \"با نصرت و فتح و ظفر و دولت والا\"\n",
        "input_text = \"توانا بود هر که دانا بود\"\n",
        "input_text = \"دست     \"\n",
        "input_text = \"ای دل \"\n",
        "input_text = \"تو خوشگل ناز منی \"\n",
        "\n",
        "\n",
        "\n",
        "# Define maximum BOM count\n",
        "max_bom_count = 20\n",
        "\n",
        "# Accumulate the complete generated text\n",
        "complete_text = input_text\n",
        "\n",
        "# Track the last few generated tokens\n",
        "repetition_threshold = 5\n",
        "last_few_tokens = []\n",
        "temperature = 0.7\n",
        "\n",
        "# Generate text in a loop until the maximum BOM count is reached\n",
        "bom_count = 0\n",
        "\n",
        "while bom_count < max_bom_count:\n",
        "    predicted_text = get_model_output(model, input_text, config, temperature=0.7, top_k=50)\n",
        "\n",
        "    # Prevent repeating sequences and filter invalid tokens\n",
        "    #if predicted_text.strip() in last_few_tokens or not is_valid_token(predicted_text.strip()):\n",
        "    #    temperature *= 1.1  # Increase temperature to promote diversity\n",
        "    #    predicted_text = get_model_output(model, input_text, config, temperature=temperature, top_k=50)\n",
        "    #else:\n",
        "    #    temperature = max(0.7, temperature * 0.95)  # Gradually decrease temperature back to a minimum\n",
        "\n",
        "    complete_text += ' ' + predicted_text.strip()  # Ensure proper spacing\n",
        "    last_few_tokens.append(predicted_text.strip())\n",
        "\n",
        "    if len(last_few_tokens) > repetition_threshold:\n",
        "        last_few_tokens.pop(0)\n",
        "\n",
        "    # Truncate the input text if it exceeds the block size\n",
        "    input_text += ' ' + predicted_text.strip()\n",
        "    input_ids = tokenize_and_truncate_text(input_text, block_size)\n",
        "    input_text = tokenizer.decode(input_ids[0].tolist())  # Update input_text to truncated version\n",
        "\n",
        "    # Add a new line after [EOS]\n",
        "    if '[EOS]' and '[BOM]' in predicted_text:\n",
        "        complete_text += '\\n'\n",
        "        bom_count += 1\n",
        "\n",
        "# Print the whole output after the loop\n",
        "print(f\"Predicted Text:\\n{complete_text}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "56d16ec7385d44cbbd916dd359aad478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7542ccc785ea4361945dd2b2160163aa",
              "IPY_MODEL_94fe15d8314d4fdeb576107a94988666",
              "IPY_MODEL_ecd89974d0a5468093faadd8e5ddd927"
            ],
            "layout": "IPY_MODEL_58d10890af7f4561907c67e32bf20400"
          }
        },
        "7542ccc785ea4361945dd2b2160163aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f657990ba6a4097b97fc5e35b419492",
            "placeholder": "​",
            "style": "IPY_MODEL_63617afcff8c4cca918a8f83af8c8b51",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "94fe15d8314d4fdeb576107a94988666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fda3ba1335f04d179ba0ec2a08053b8c",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dd1ecb8d2d145deb96cd628f39dc2e4",
            "value": 350
          }
        },
        "ecd89974d0a5468093faadd8e5ddd927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab435adb76f4e49947744dad9e563dc",
            "placeholder": "​",
            "style": "IPY_MODEL_25a2dffe6754497c99544d028f08ab56",
            "value": " 350/350 [00:00&lt;00:00, 27.3kB/s]"
          }
        },
        "58d10890af7f4561907c67e32bf20400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f657990ba6a4097b97fc5e35b419492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63617afcff8c4cca918a8f83af8c8b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fda3ba1335f04d179ba0ec2a08053b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dd1ecb8d2d145deb96cd628f39dc2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ab435adb76f4e49947744dad9e563dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a2dffe6754497c99544d028f08ab56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67d0f121b6dc4f30a01ff462e39709dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bdf70cab4e44cc6a7af757ac64eb443",
              "IPY_MODEL_b28bcd04c43f4007bd78067abc475a4e",
              "IPY_MODEL_aa3a2c8c9cc8464f9cb1fef3f0157f56"
            ],
            "layout": "IPY_MODEL_26da59ea42bc47dba27e235e35f6c808"
          }
        },
        "3bdf70cab4e44cc6a7af757ac64eb443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_608b7954682447a28713acaee22d377b",
            "placeholder": "​",
            "style": "IPY_MODEL_24abd7239b5541f98a7f82940e694794",
            "value": "config.json: 100%"
          }
        },
        "b28bcd04c43f4007bd78067abc475a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a00eecb38c3459cbf12c48af11fa115",
            "max": 1331,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fd706a34a824a9b82d52e48113d6ab6",
            "value": 1331
          }
        },
        "aa3a2c8c9cc8464f9cb1fef3f0157f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91845f6d7ef4d329077f4de96c4d9dd",
            "placeholder": "​",
            "style": "IPY_MODEL_09b216a689784d4390174b802dcaffc3",
            "value": " 1.33k/1.33k [00:00&lt;00:00, 105kB/s]"
          }
        },
        "26da59ea42bc47dba27e235e35f6c808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608b7954682447a28713acaee22d377b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24abd7239b5541f98a7f82940e694794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a00eecb38c3459cbf12c48af11fa115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fd706a34a824a9b82d52e48113d6ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a91845f6d7ef4d329077f4de96c4d9dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b216a689784d4390174b802dcaffc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9373d88fb9c24cbb99a6f5aaec21ab08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f03f1b749e94496e890ad346c1997914",
              "IPY_MODEL_88d8b80d7ef44242814a2e17b310de7a",
              "IPY_MODEL_9cf557e64b9c4003aa3eac3d414ba6ce"
            ],
            "layout": "IPY_MODEL_431a9c80bd8d45adb208022a98aee22c"
          }
        },
        "f03f1b749e94496e890ad346c1997914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1872a2c0e04249afa131a0f43bef261e",
            "placeholder": "​",
            "style": "IPY_MODEL_a04611d925e04a85998f57675ba2e88c",
            "value": "spiece.model: 100%"
          }
        },
        "88d8b80d7ef44242814a2e17b310de7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d015498be6d24bada6134eedac6a8f03",
            "max": 537052,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f744b873339439583b0fc8c94e8893d",
            "value": 537052
          }
        },
        "9cf557e64b9c4003aa3eac3d414ba6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_858e6fb8428846239cf819b7a49b4462",
            "placeholder": "​",
            "style": "IPY_MODEL_ec5214000ff04809aa880d9e2506e559",
            "value": " 537k/537k [00:00&lt;00:00, 1.25MB/s]"
          }
        },
        "431a9c80bd8d45adb208022a98aee22c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1872a2c0e04249afa131a0f43bef261e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a04611d925e04a85998f57675ba2e88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d015498be6d24bada6134eedac6a8f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f744b873339439583b0fc8c94e8893d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "858e6fb8428846239cf819b7a49b4462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec5214000ff04809aa880d9e2506e559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "507d0cbb586e4da992465b61caac68d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_300b84025dda475095fc90dfc4f7d5f5",
              "IPY_MODEL_6d586e9e07fb49ec8ee6a602b3e2cf4a",
              "IPY_MODEL_6604d2ab3779422a86749fc21849b53a"
            ],
            "layout": "IPY_MODEL_503c0be0338a4adebdc241e681b18017"
          }
        },
        "300b84025dda475095fc90dfc4f7d5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7d6b8706c224bbaa846aa1a7bd6bbcd",
            "placeholder": "​",
            "style": "IPY_MODEL_8bc1b73d7bf44399a308d787e22ac67f",
            "value": "tokenizer.json: 100%"
          }
        },
        "6d586e9e07fb49ec8ee6a602b3e2cf4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9abc4e77cabd4fd0b7555076079bce1d",
            "max": 1127358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38c43f8701214916a5c4a833b25cda91",
            "value": 1127358
          }
        },
        "6604d2ab3779422a86749fc21849b53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_075f1c2b1f9b47258ad5bdc17f85fe8d",
            "placeholder": "​",
            "style": "IPY_MODEL_cabf34c1ae12466aa46d1d9904ed0e15",
            "value": " 1.13M/1.13M [00:00&lt;00:00, 2.62MB/s]"
          }
        },
        "503c0be0338a4adebdc241e681b18017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d6b8706c224bbaa846aa1a7bd6bbcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc1b73d7bf44399a308d787e22ac67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9abc4e77cabd4fd0b7555076079bce1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38c43f8701214916a5c4a833b25cda91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "075f1c2b1f9b47258ad5bdc17f85fe8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cabf34c1ae12466aa46d1d9904ed0e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d17558a52b9496184a513ff52f4b9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7147f7f170624496ab5ebce9bb05653c",
              "IPY_MODEL_d6791e267c04475d826e9f15b18db30d",
              "IPY_MODEL_9c4a54279e64412da319d4f512e1b4ec"
            ],
            "layout": "IPY_MODEL_6fd0c7cf17154acebd8d7667b29a320d"
          }
        },
        "7147f7f170624496ab5ebce9bb05653c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2657bd41d839423ebdb191d34c09f970",
            "placeholder": "​",
            "style": "IPY_MODEL_1a7ab9d3d3b54419a7fdf8c7230b88d4",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d6791e267c04475d826e9f15b18db30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5add76e0db484c8f42767726d8c5ee",
            "max": 399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22b38418fab342aca9d49ff5bae803fe",
            "value": 399
          }
        },
        "9c4a54279e64412da319d4f512e1b4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b61de9594416454086b719d9d9adb1e2",
            "placeholder": "​",
            "style": "IPY_MODEL_dfb4793d3438420ebabf782adc6d7496",
            "value": " 399/399 [00:00&lt;00:00, 36.8kB/s]"
          }
        },
        "6fd0c7cf17154acebd8d7667b29a320d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2657bd41d839423ebdb191d34c09f970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7ab9d3d3b54419a7fdf8c7230b88d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f5add76e0db484c8f42767726d8c5ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22b38418fab342aca9d49ff5bae803fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b61de9594416454086b719d9d9adb1e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb4793d3438420ebabf782adc6d7496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}