{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7747c31e-c592-4cdc-b5ed-ab9656fe39be",
      "metadata": {
        "id": "7747c31e-c592-4cdc-b5ed-ab9656fe39be"
      },
      "source": [
        "# Small GPT, little update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f9615469-6d91-40ba-a58c-066f3c7e4097",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9615469-6d91-40ba-a58c-066f3c7e4097",
        "outputId": "05100d5d-df59-4f73-8757-2aebeb62336f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install transformers\n",
        "#!pip install huggingface_hub\n",
        "#!pip install transformers\n",
        "!pip install kaggle\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6fb38020-c7a1-4756-bebc-a7ca896c5677",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fb38020-c7a1-4756-bebc-a7ca896c5677",
        "outputId": "a1497c78-3df8-442c-f298-13ad0952f394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. GPU is ready for use.\n",
            "Device Name: NVIDIA L4\n",
            "Number of GPUs available: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. GPU is ready for use.\")\n",
        "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
        "else:\n",
        "    print(\"CUDA is not available. Running on CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "id": "IsfL2pzPzfD9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "778977f4-bc0d-496b-e861-f231159c5bc4"
      },
      "id": "IsfL2pzPzfD9",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-92cbc976-135c-498d-aa6f-d6bde0bac64a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-92cbc976-135c-498d-aa6f-d6bde0bac64a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ajazbi\",\"key\":\"b05383cb636da48dedb1a00d1b53c555\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "QZ_VQ5Pd1FXH"
      },
      "id": "QZ_VQ5Pd1FXH",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n"
      ],
      "metadata": {
        "id": "GLNWDs1s1JVD"
      },
      "id": "GLNWDs1s1JVD",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7f88c813-2c60-434f-9dcf-33a704353a90",
      "metadata": {
        "id": "7f88c813-2c60-434f-9dcf-33a704353a90"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import pickle\n",
        "from contextlib import nullcontext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "from collections import Counter\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.distributed import init_process_group, destroy_process_group\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import inspect\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from transformers import AutoTokenizer\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "682b94f6-30b4-4b89-8843-4ba1423bc159",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "682b94f6-30b4-4b89-8843-4ba1423bc159",
        "outputId": "bfc5435e-1987-45ce-ae30-05fd5e0b02f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/aminghd/large-corpus-of-farsi-poems\n",
            "Dataset URL: https://www.kaggle.com/datasets/aminghd/large-corpus-of-farsi-poems\n",
            "Dataset URL: https://www.kaggle.com/datasets/aminghd/large-corpus-of-farsi-poems\n",
            "Dataset URL: https://www.kaggle.com/datasets/aminghd/large-corpus-of-farsi-poems\n",
            "Dataset URL: https://www.kaggle.com/datasets/aminghd/large-corpus-of-farsi-poems\n",
            "Dataset URL: https://www.kaggle.com/datasets/aminghd/large-corpus-of-farsi-poems\n",
            "Dataset URL: https://www.kaggle.com/datasets/aminghd/large-corpus-of-farsi-poems\n",
            "Dataset URL: https://www.kaggle.com/datasets/aminghd/large-corpus-of-farsi-poems\n",
            "Total words: 944050\n",
            "Max line length: 15 words\n",
            "Total number of lines: 132822\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Authenticate with Kaggle\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Define Kaggle dataset details\n",
        "dataset = 'aminghd/large-corpus-of-farsi-poems'\n",
        "#file_name = 'parvin_norm.txt'\n",
        "file_names = ['parvin_norm.txt', 'eraghi_norm.txt', 'farrokhi_norm.txt',\n",
        "              'helali_norm.txt', 'gilani_norm.txt', 'khosro_norm.txt'\n",
        "              , 'salman_norm.txt', 'shahriar_norm.txt']  # Add more file names as needed\n",
        "\n",
        "# Initialize variables to store the word count, max line length, and number of lines\n",
        "total_words = 0\n",
        "max_line_length = 0\n",
        "num_lines = 0\n",
        "\n",
        "# Initialize an empty list to store the formatted lines\n",
        "formatted_lines = []\n",
        "\n",
        "for file_name in file_names:\n",
        "    # Download the specific file from the Kaggle dataset\n",
        "    api.dataset_download_file(dataset, file_name)\n",
        "\n",
        "    # Check if the file is downloaded and unzipped correctly\n",
        "    if not os.path.exists(file_name):\n",
        "        os.system(f'unzip {file_name}.zip')\n",
        "\n",
        "    # Read the content of the text file\n",
        "    with open(file_name, 'r', encoding='utf-8') as file:\n",
        "        lines = [line.strip() for line in file.readlines() if line.strip()]\n",
        "\n",
        "    # Iterate over the lines in pairs and format them with special tokens\n",
        "    for i in range(0, len(lines), 2):\n",
        "        if i + 1 < len(lines) and lines[i] and lines[i + 1]:\n",
        "            formatted_line = f\"[BOM] {lines[i]} [BOM] {lines[i+1]}[EOS]\"\n",
        "            formatted_lines.append(formatted_line)\n",
        "\n",
        "            # Update line and word counts\n",
        "            words_in_first_line = len(lines[i].split())\n",
        "            words_in_second_line = len(lines[i + 1].split())\n",
        "\n",
        "            total_words += words_in_first_line + words_in_second_line\n",
        "            max_line_length = max(max_line_length, words_in_first_line, words_in_second_line)\n",
        "            num_lines += 2  # Add 2 for each valid pair\n",
        "\n",
        "# Join the formatted lines into a single string\n",
        "sentences = \"\\n\".join(formatted_lines)\n",
        "\n",
        "# Print the entire formatted content\n",
        "# print(sentences)\n",
        "\n",
        "# Print the counts\n",
        "print(f\"Total words: {total_words}\")\n",
        "print(f\"Max line length: {max_line_length} words\")\n",
        "print(f\"Total number of lines: {num_lines}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3de8952a-3ec1-4bb7-b159-85e1ce1a6d56",
      "metadata": {
        "id": "3de8952a-3ec1-4bb7-b159-85e1ce1a6d56",
        "outputId": "e5317715-c578-486e-adaf-905681a47d1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words: 38539\n"
          ]
        }
      ],
      "source": [
        "# Function to clean and count word frequencies\n",
        "def count_word_frequencies(text):\n",
        "    # Remove special tokens\n",
        "    cleaned_text = re.sub(r'\\[BOM\\]|\\[EOS\\]', '', text)\n",
        "\n",
        "    # Split text into words\n",
        "    words = cleaned_text.split()\n",
        "\n",
        "    # Count word frequencies\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    return word_counts\n",
        "\n",
        "# Count word frequencies in the formatted content\n",
        "word_frequencies = count_word_frequencies(sentences)\n",
        "\n",
        "# Get the number of unique words\n",
        "num_unique_words = len(word_frequencies)\n",
        "\n",
        "# Sort word frequencies from highest to lowest\n",
        "sorted_word_frequencies = word_frequencies.most_common()\n",
        "\n",
        "# Print the total number of unique words\n",
        "print(f'Total unique words: {num_unique_words}')\n",
        "\n",
        "# Print word frequencies from highest to lowest\n",
        "#for word, freq in sorted_word_frequencies:\n",
        "#    print(f'{word}: {freq}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e21c056f-0be4-48c5-8a54-a71d11bb32dc",
      "metadata": {
        "id": "e21c056f-0be4-48c5-8a54-a71d11bb32dc",
        "outputId": "f4d2f90d-ca07-49b2-fafe-d5e6eeb0d666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "cfc515a8f59d4fc382326e12229bad83",
            "6fe20223a16f43bb9596ad985315c4f4",
            "4ebf9a19837345198314ccedc05e95fd",
            "e22055a2213d473580570f335294b651",
            "be45d82c3513446783ca413417fdfa31",
            "aaa82e85d8b84f39805001040e26bf97",
            "806bbe76849248d48434bdc293627780",
            "b3b10dc13699437fad10898105dd6ecc",
            "db460f022ff344c8a27f04d1e1fb3fce",
            "ec0face07da34ffb995c34faf96148d5",
            "1174aafaee5f4f33a3d1b09970044b57",
            "f5a9c1f666a647a9b84b115116ee5c78",
            "658ad4bcfdb5416ab011a7280ba6e52d",
            "d47dc3fbdc1a464399e4b6ba4b53fa4a",
            "84d9b45abc8d4a52a3b55d1a634a8e5f",
            "6bb54a0ce43043e892fd78c1c1bccb2d",
            "cbcda56347ab4d57ac20f763091da5da",
            "a6256014ae88439ca75293cc345ddcbe",
            "08034eaca41346c984203d9372946955",
            "f9451733032542658f07aa90417968d2",
            "2a7da95489c14578a24e6cf956d720f4",
            "f95323e68cd7468fbe94b29dfb13d90c",
            "26b2757b11004fc3b74e96ebbccc1ba2",
            "081a32d5dfd54c3a860899093e789a7d",
            "81f1cbf854da4fb591233a7d2a71bd8b",
            "c2233d53b9084ab8a1e33ff02430d38e",
            "76e1674758ac4c45b0c319492d1eef3c",
            "49bfe95de3344d0e910e94c34100446b",
            "6bfef887d4864bbe99e8950a77da5151",
            "5e8df18c74074262a388e5c69d7b31c8",
            "ced7135ecdfc4206929b004dacfa5d78",
            "4f0482bfbb3c45bcb9f8bf23f0ad82a1",
            "12c5dc9a501647b992ea5f3f63408fdb",
            "7cb4368797ae4032829325edc1e6c8a8",
            "8ba9eada88d54ba2ab7c4eadabc8006f",
            "eb8328e1eecb4bf59a26fb6e2abe2049",
            "c722b112780942d1b09c2b8e8252a2fa",
            "28b421b4bbe14c7688b782296284efa7",
            "7aaeefa03b5e42c983af877923044e0b",
            "4e4e90660cdf45aa8dc7fa8aa2ae4597",
            "7523f96d578844a78a86a83c6acb4191",
            "c1c79e7f0e28448098a20cf5df50b430",
            "193301b07794490786b2a0402ce7cae5",
            "ea8b8d7b74bb4bef9a5f1ad85fa6e8d7",
            "a0611c00bf1e44d8b1e8a08ee894d430",
            "f33e5b822b774b1b8ebdfedfef9bafb6",
            "75a69bb7c61147c895623c69d7835436",
            "6f7183a2025d4c86a0cbd234d4eeed00",
            "4c349d4d2bf6438697d371c2098a2d95",
            "204d92e96c2e4c9a84e4ac34cf9894b4",
            "f85e4637940f4bd3acb1257c5bf1a17b",
            "b6ac0a325dad4bccadccb2458bdc6479",
            "eaff2a4f15a341c3af40198d887301d8",
            "6b7e2ab5cb474aef8c31c4e6980003cd",
            "5bac0e89fe6040d7a2dc0205eac30a19"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 66411\n",
            "Number of training sentences: 59769\n",
            "Number of validation sentences: 6642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfc515a8f59d4fc382326e12229bad83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5a9c1f666a647a9b84b115116ee5c78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/537k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26b2757b11004fc3b74e96ebbccc1ba2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.13M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cb4368797ae4032829325edc1e6c8a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0611c00bf1e44d8b1e8a08ee894d430"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data has 1,112,579 tokens\n",
            "Validation data has 120,093 tokens\n",
            "Training data saved to ./trainF.bin\n",
            "Validation data saved to ./valF.bin\n"
          ]
        }
      ],
      "source": [
        "sentences=formatted_lines\n",
        "# Check the number of sentences\n",
        "num_sentences = len(sentences)\n",
        "print(f\"Number of sentences: {num_sentences}\")\n",
        "\n",
        "# Ensure there are enough sentences to split\n",
        "if num_sentences > 1:\n",
        "    # Calculate the split index\n",
        "    split_index = int(num_sentences * 0.9)\n",
        "\n",
        "    # Split data into training and validation sets (90% training, 10% validation)\n",
        "    train_sentences = sentences[:split_index]\n",
        "    val_sentences = sentences[split_index:]\n",
        "\n",
        "    # Concatenate all training and validation sentences into single texts\n",
        "    train_text = ' '.join(train_sentences)\n",
        "    val_text = ' '.join(val_sentences)\n",
        "\n",
        "    print(f\"Number of training sentences: {len(train_sentences)}\")\n",
        "    print(f\"Number of validation sentences: {len(val_sentences)}\")\n",
        "else:\n",
        "    print(\"Not enough sentences to split. Please provide more data.\")\n",
        "\n",
        "# Load a Persian-specific tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "#tokenizer = AutoTokenizer.from_pretrained('HooshvareLab/gpt2-fa')\n",
        "\n",
        "# Encode the data using the Persian-specific tokenizer\n",
        "train_ids = tokenizer.encode(train_text, add_special_tokens=False)\n",
        "\n",
        "val_ids = tokenizer.encode(val_text, add_special_tokens=False)\n",
        "\n",
        "print(f\"Training data has {len(train_ids):,} tokens\")\n",
        "print(f\"Validation data has {len(val_ids):,} tokens\")\n",
        "\n",
        "# Convert to NumPy arrays and save to binary files  # <-- Changed to uint32\n",
        "train_ids = np.array(train_ids, dtype=np.uint32)\n",
        "val_ids = np.array(val_ids, dtype=np.uint32)\n",
        "\n",
        "# Define paths for output files\n",
        "output_dir = '.'  # You can update this to any directory you want\n",
        "train_output_path = os.path.join(output_dir, 'trainF.bin')\n",
        "val_output_path = os.path.join(output_dir, 'valF.bin')\n",
        "\n",
        "# Save to binary files\n",
        "train_ids.tofile(train_output_path)\n",
        "val_ids.tofile(val_output_path)\n",
        "\n",
        "print(f\"Training data saved to {train_output_path}\")\n",
        "print(f\"Validation data saved to {val_output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "30b1adbd-d079-4e86-a2f9-e98b0dc0ca66",
      "metadata": {
        "id": "30b1adbd-d079-4e86-a2f9-e98b0dc0ca66",
        "outputId": "f92f49f4-bc0a-434a-e948-a9b403dd1ffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Sample:\n",
            "[BOM] ای دل عبث مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک را و ببین آنگه[BOM] بی مهری زمانه رسوا را[EOS][BOM] این دشت خوابگاه شهیدانست[BOM] فرصت شمار وقت تماشا را[EOS][BOM] از عمر رفته نیز شماری کن\n",
            "\n",
            "Validation Data Sample:\n",
            "[BOM] ای دل خود پرست سودایی[BOM] چند بر خاک باد پیمایی[EOS][BOM] توده خاکی آن نمی ارزد[BOM] که تو دامن بدان بیالایی[EOS][BOM] آفتابی نهان به سایه گل[BOM] گل چه بر آفتاب اندایی[EOS][BOM] آفتابا عجب چه خورشیدی[BOM] که تو با سایه بر نمی آیی[EOS][BOM] مطربا پرده\n"
          ]
        }
      ],
      "source": [
        "sample_size=64\n",
        "print(\"Training Data Sample:\")\n",
        "print(tokenizer.decode(train_ids[:sample_size]))\n",
        "\n",
        "print(\"\\nValidation Data Sample:\")\n",
        "print(tokenizer.decode(val_ids[:sample_size]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "572ed86e-ac81-4a4e-8f1d-1a18202d05a6",
      "metadata": {
        "id": "572ed86e-ac81-4a4e-8f1d-1a18202d05a6"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset class\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, data, block_size):\n",
        "        self.data = data\n",
        "        self.block_size = block_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.data[idx:idx + self.block_size], dtype=torch.long)\n",
        "        y = torch.tensor(self.data[idx + 1:idx + 1 + self.block_size], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "# Filtering function\n",
        "def filter_indices(data, max_index):\n",
        "    return [idx for idx in data if idx < max_index]\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
        "\n",
        "    def __init__(self, ndim, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        # regularization\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.dropout = config.dropout\n",
        "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
        "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
        "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                        .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        if self.flash:\n",
        "            # efficient attention using Flash Attention CUDA kernels\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
        "        else:\n",
        "            # manual implementation of attention\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.gelu    = nn.GELU()\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight  # Weight tying\n",
        "\n",
        "        # Init all weights\n",
        "        self.apply(self._init_weights)\n",
        "        # Apply special scaled init to the residual projections, per GPT-2 paper\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        # Report number of parameters\n",
        "        print(\"number of parameters: %.2fM\" % (self.get_num_params() / 1e6,))\n",
        "\n",
        "    def get_num_params(self, non_embedding=True):\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        if non_embedding:\n",
        "            n_params -= self.transformer.wpe.weight.numel()\n",
        "        return n_params\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device)  # shape (t)\n",
        "\n",
        "        # Forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx)  # token embeddings of shape (b, t, n_embd)\n",
        "        pos_emb = self.transformer.wpe(pos)  # position embeddings of shape (t, n_embd)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            # If we are given some desired targets also calculate the loss\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "        else:\n",
        "            # Inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "            logits = self.lm_head(x[:, [-1], :])  # note: using list [-1] to preserve the time dim\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
        "        # start with all of the candidate parameters\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        # filter out those that do not require grad\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {'params': decay_params, 'weight_decay': weight_decay},\n",
        "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "        # Create AdamW optimizer and use the fused version if it is available\n",
        "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "        use_fused = fused_available and device_type == 'cuda'\n",
        "        extra_args = dict(fused=True) if use_fused else dict()\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
        "        print(f\"using fused AdamW: {use_fused}\")\n",
        "\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "484985e9-f86f-4f5f-8d45-717d6b54c1a2",
      "metadata": {
        "id": "484985e9-f86f-4f5f-8d45-717d6b54c1a2",
        "outputId": "13e613da-840c-4ec1-c7f5-8371228a7acb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 11.13M\n",
            "GPT(\n",
            "  (transformer): ModuleDict(\n",
            "    (wte): Embedding(24954, 256)\n",
            "    (wpe): Embedding(32, 256)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-5): 6 x Block(\n",
            "        (ln_1): LayerNorm()\n",
            "        (attn): CausalSelfAttention(\n",
            "          (c_attn): Linear(in_features=256, out_features=768, bias=True)\n",
            "          (c_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm()\n",
            "        (mlp): MLP(\n",
            "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (gelu): GELU(approximate='none')\n",
            "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=256, out_features=24954, bias=False)\n",
            ")\n",
            "vocab_size= 24954\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int\n",
        "    vocab_size: int\n",
        "    n_layer: int\n",
        "    n_head: int\n",
        "    n_embd: int  # n_embd must be divisible by n_head\n",
        "    dropout: float\n",
        "    bias: bool\n",
        "\"\"\"\n",
        "config = GPTConfig(\n",
        "    block_size=64,\n",
        "    vocab_size= max(max(train_ids), max(val_ids)) + 1,\n",
        "    n_layer=4,\n",
        "    n_head=4,\n",
        "    n_embd=64,  # Ensure n_embd is divisible by n_head\n",
        "    dropout=0.1,\n",
        "    bias=True\n",
        ")\n",
        "\"\"\"\n",
        "config = GPTConfig(\n",
        "    block_size=32,\n",
        "    vocab_size= max(max(train_ids), max(val_ids)) + 1,\n",
        "    n_layer=6,\n",
        "    n_head=8,\n",
        "    n_embd=256,  # Ensure n_embd is divisible by n_head\n",
        "    dropout=0.1,\n",
        "    bias=True\n",
        ")\n",
        "\n",
        "\n",
        "model = GPT(config)\n",
        "print(model)\n",
        "\n",
        "print (\"vocab_size=\" , max(max(train_ids), max(val_ids)) + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "84823ac5-2153-4215-a016-1c6d6200e9b0",
      "metadata": {
        "id": "84823ac5-2153-4215-a016-1c6d6200e9b0",
        "outputId": "29de089b-10bc-443c-dc1e-b6b4cb3edce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Training Dataset: 1112547\n",
            "Size of Validation Dataset: 120061\n",
            "Train Dataset Samples as Numbers:\n",
            "Sample 1 as numbers\n",
            "x: [    7   213   128 12695  9436   464   357    53     7  9688  1960  5530\n",
            "  1284    53     9     7  4745  3477   204  1697 17653    56     7   129\n",
            "  4402    55  1331 16421    53     9     7 17105]\n",
            "y: [  213   128 12695  9436   464   357    53     7  9688  1960  5530  1284\n",
            "    53     9     7  4745  3477   204  1697 17653    56     7   129  4402\n",
            "    55  1331 16421    53     9     7 17105   416]\n",
            "--------------------------------------------------\n",
            "Sample 2 as numbers\n",
            "x: [  213   128 12695  9436   464   357    53     7  9688  1960  5530  1284\n",
            "    53     9     7  4745  3477   204  1697 17653    56     7   129  4402\n",
            "    55  1331 16421    53     9     7 17105   416]\n",
            "y: [  128 12695  9436   464   357    53     7  9688  1960  5530  1284    53\n",
            "     9     7  4745  3477   204  1697 17653    56     7   129  4402    55\n",
            "  1331 16421    53     9     7 17105   416    53]\n",
            "--------------------------------------------------\n",
            "Sample 3 as numbers\n",
            "x: [  128 12695  9436   464   357    53     7  9688  1960  5530  1284    53\n",
            "     9     7  4745  3477   204  1697 17653    56     7   129  4402    55\n",
            "  1331 16421    53     9     7 17105   416    53]\n",
            "y: [12695  9436   464   357    53     7  9688  1960  5530  1284    53     9\n",
            "     7  4745  3477   204  1697 17653    56     7   129  4402    55  1331\n",
            " 16421    53     9     7 17105   416    53    45]\n",
            "--------------------------------------------------\n",
            "Sample 4 as numbers\n",
            "x: [12695  9436   464   357    53     7  9688  1960  5530  1284    53     9\n",
            "     7  4745  3477   204  1697 17653    56     7   129  4402    55  1331\n",
            " 16421    53     9     7 17105   416    53    45]\n",
            "y: [ 9436   464   357    53     7  9688  1960  5530  1284    53     9     7\n",
            "  4745  3477   204  1697 17653    56     7   129  4402    55  1331 16421\n",
            "    53     9     7 17105   416    53    45  2423]\n",
            "--------------------------------------------------\n",
            "Sample 5 as numbers\n",
            "x: [ 9436   464   357    53     7  9688  1960  5530  1284    53     9     7\n",
            "  4745  3477   204  1697 17653    56     7   129  4402    55  1331 16421\n",
            "    53     9     7 17105   416    53    45  2423]\n",
            "y: [  464   357    53     7  9688  1960  5530  1284    53     9     7  4745\n",
            "  3477   204  1697 17653    56     7   129  4402    55  1331 16421    53\n",
            "     9     7 17105   416    53    45  2423  5349]\n",
            "--------------------------------------------------\n",
            "\n",
            "Train Dataset Samples as Text:\n",
            "Sample 1 as text\n",
            "x: [BOM] ای دل عبث مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف\n",
            "y: ای دل عبث مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک\n",
            "--------------------------------------------------\n",
            "Sample 2 as text\n",
            "x: ای دل عبث مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک\n",
            "y: دل عبث مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک را\n",
            "--------------------------------------------------\n",
            "Sample 3 as text\n",
            "x: دل عبث مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک را\n",
            "y: عبث مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک را و\n",
            "--------------------------------------------------\n",
            "Sample 4 as text\n",
            "x: عبث مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک را و\n",
            "y: مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک را و ببین\n",
            "--------------------------------------------------\n",
            "Sample 5 as text\n",
            "x: مخور غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک را و ببین\n",
            "y: غم دنیا را[BOM] فکرت مکن نیامده فردا را[EOS][BOM] کنج قفس چو نیک بیندیشی[BOM] چون گلشن است مرغ شکیبا را[EOS][BOM] بشکاف خاک را و ببین آنگه\n",
            "--------------------------------------------------\n",
            "Number of batches in Training DataLoader: 34768\n",
            "Number of batches in Validation DataLoader: 3752\n",
            "num decayed parameter tensors: 26, with 11,115,008 parameters\n",
            "num non-decayed parameter tensors: 50, with 20,480 parameters\n",
            "using fused AdamW: True\n"
          ]
        }
      ],
      "source": [
        "def decode_sample(ids, sample_size):\n",
        "    sample_ids = ids[:sample_size]\n",
        "    sample_text = tokenizer.decode(sample_ids.tolist())\n",
        "    return sample_text\n",
        "\n",
        "# making data and check it\n",
        "gradient_accumulation_steps = 1 # 5 * 8 # used to simulate larger batch sizes\n",
        "batch_size = 32 # if gradient_accumulation_steps > 1, this is the micro-batch size\n",
        "\n",
        "# Create Datasets\n",
        "train_dataset = GPTDataset(train_ids, config.block_size)\n",
        "val_dataset = GPTDataset(val_ids, config.block_size)\n",
        "\n",
        "# Print sizes of the datasets\n",
        "print(f\"Size of Training Dataset: {len(train_dataset)}\")\n",
        "print(f\"Size of Validation Dataset: {len(val_dataset)}\")\n",
        "\n",
        "# Function to print a few samples as numbers\n",
        "def print_samples_as_numbers(dataset, num_samples=5):\n",
        "    for i in range(num_samples):\n",
        "        x, y = dataset[i]\n",
        "        print(f\"Sample {i + 1} as numbers\")\n",
        "        print(f\"x: {x.numpy()}\")\n",
        "        print(f\"y: {y.numpy()}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# Function to print a few samples as decoded text\n",
        "def print_samples_as_text(dataset, num_samples=5):\n",
        "    for i in range(num_samples):\n",
        "        x, y = dataset[i]\n",
        "        x_text = decode_sample(x, sample_size)\n",
        "        y_text = decode_sample(y, sample_size)\n",
        "        print(f\"Sample {i + 1} as text\")\n",
        "        print(f\"x: {x_text}\")\n",
        "        print(f\"y: {y_text}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# Print samples from the train dataset as numbers\n",
        "print(\"Train Dataset Samples as Numbers:\")\n",
        "print_samples_as_numbers(train_dataset)\n",
        "\n",
        "# Print  samples from the train dataset as text\n",
        "print(\"\\nTrain Dataset Samples as Text:\")\n",
        "print_samples_as_text(train_dataset)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Print size of DataLoader\n",
        "num_train_batches = len(train_loader)\n",
        "num_val_batches = len(val_loader)\n",
        "print(f\"Number of batches in Training DataLoader: {num_train_batches}\")\n",
        "print(f\"Number of batches in Validation DataLoader: {num_val_batches}\")\n",
        "\n",
        "\n",
        "# Initialize optimizer\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)  # Ensure the model is on the correct device\n",
        "optimizer = model.configure_optimizers(weight_decay=0.1, learning_rate=3e-4, betas=(0.9, 0.95), device_type=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9d4f1dba-5738-4bad-9cc4-ca6ff0cb62f9",
      "metadata": {
        "id": "9d4f1dba-5738-4bad-9cc4-ca6ff0cb62f9"
      },
      "outputs": [],
      "source": [
        "# Define the learning rate scheduler\n",
        "\n",
        "# Global variables for learning rate scheduling\n",
        "decay_lr = True  # whether to decay the learning rate\n",
        "warmup_iters = 2000  # how many steps to warm up for\n",
        "lr_decay_iters = 600000  # should be ~= max_iters per Chinchilla\n",
        "min_lr = 6e-5  # minimum learning rate, should be ~= learning_rate/10 per Chinchilla\n",
        "learning_rate = 3e-4  # initial learning rate\n",
        "\n",
        "def get_lr(it):\n",
        "    # 1) Linear warmup for warmup_iters steps\n",
        "    if it < warmup_iters:\n",
        "        return learning_rate * it / warmup_iters\n",
        "    # 2) If it > lr_decay_iters, return min learning rate\n",
        "    if it > lr_decay_iters:\n",
        "        return min_lr\n",
        "    # 3) In between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))  # coeff ranges 0..1\n",
        "    return min_lr + coeff * (learning_rate - min_lr)\n",
        "\n",
        "def print_sample_as_text(x, y, train_val):\n",
        "    random_idx = random.randint(0, x.size(0) - 1)  # Get a random index from the batch\n",
        "    x_text = decode_data(x[random_idx])\n",
        "    y_text = decode_data(y[random_idx])\n",
        "    print(\"Random Sample as text from  \", train_val)\n",
        "    print(f\"x: {x_text}\")\n",
        "    print(f\"y: {y_text}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "def decode_data(ids):\n",
        "    sample_ids = ids.tolist()  # Convert tensor to list of integers\n",
        "    sample_text = tokenizer.decode(sample_ids)\n",
        "    return sample_text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "eX6qtsJePNED"
      },
      "id": "eX6qtsJePNED",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d94a53-c631-4fd3-9e27-060d96aefcf9",
      "metadata": {
        "id": "c0d94a53-c631-4fd3-9e27-060d96aefcf9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# new training function with validation every 50 epoch\n",
        "def train(model, train_loader, val_loader, optimizer, config, epochs=1, gradient_accumulation_steps=1):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    iter_num = 0\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        total_loss = 0.0\n",
        "        for batch_idx, (x, y) in enumerate(train_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # Update learning rate\n",
        "            lr = get_lr(iter_num)\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "\n",
        "            logits, loss = model(x, y)\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                iter_num += 1\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Avg Training Loss: {avg_loss:.4f}')\n",
        "\n",
        "        # Validation every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            val_loss = evaluate(model, val_loader, device)\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "            # Save the best model\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                torch.save(model.state_dict(), 'best_model.pt')\n",
        "\n",
        "def evaluate(model, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, loss = model(x, y)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "    model.train()\n",
        "    return val_loss\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, val_loader, optimizer, config, epochs=20, gradient_accumulation_steps=gradient_accumulation_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extra Training the model\n",
        "train(model, train_loader, val_loader, optimizer, config, epochs=1, gradient_accumulation_steps=gradient_accumulation_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzthPNtqEYl0",
        "outputId": "0a331028-6481-463e-9191-7200e5d8f65c"
      },
      "id": "VzthPNtqEYl0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Avg Training Loss: 2.0583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69850b19-4e6f-4fe3-908b-4dd315062099",
      "metadata": {
        "id": "69850b19-4e6f-4fe3-908b-4dd315062099",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aefa08f-9161-405a-80f9-abc39c55a79e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and optimizer state saved to GPTper_saves\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model, optimizer state, and configuration details\n",
        "save_dir = 'GPTper_saves'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "torch.save(model.state_dict(), os.path.join(save_dir, 'final_model_perchin.pt'))\n",
        "torch.save(optimizer.state_dict(), os.path.join(save_dir, 'final_optimizer_perchin.pt'))\n",
        "with open(os.path.join(save_dir, 'training_config_perchin.txt'), 'w') as f:\n",
        "    f.write(f'Epochs: {10}\\nGradient Accumulation Steps: {gradient_accumulation_steps}\\n')\n",
        "\n",
        "print(f'Model and optimizer state saved to {save_dir}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662dfe7d-0d0a-4e1a-9aba-4ca88d848519",
      "metadata": {
        "id": "662dfe7d-0d0a-4e1a-9aba-4ca88d848519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53129187-6e43-472b-e6a3-5f057e9296fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Text:\n",
            "مرغ سحر ت رسیم [BOM]\n",
            " برای سوختن و ساختن مهیا ی یم [EOS] [BOM]\n",
            " اسیر دام هوی و قرین آز شدن [BOM]\n",
            " اگر قرن هاست درس معرفت خوانی [EOS] [BOM]\n",
            " بپ ویی و همه راههای تیره و تار [BOM]\n",
            " بدانی ار همه رازهای پنهانی [EOS] [BOM]\n",
            " حیوان گشتن و تن پروری آسان ست [EOS] [BOM]\n",
            " روح پرورده کن از لقمه روحانی [EOS] [BOM]\n",
            " با خرد جان خود را که بار نیم جو                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ست رد ای عجب عیب پوشی ها کنیم [EOS] [BOM]\n",
            " و تقدیر پرش بکند یکسر [BOM]\n",
            " شاهین حوادث را افکند ش [BOM]\n",
            " فرو برد شیر دادی رهزن [EOS] [BOM]\n",
            " بنای این همه جا سبک ساری است [BOM]\n",
            " [BOM]\n",
            " [BOM]\n",
            " تو درین ره ل است [EOS] [BOM]\n",
            " در بازی است [BOM]\n",
            " در بازی است جهان [BOM]\n",
            " تو در زی ایمن خویش روشن است [BOM]\n",
            " بساط ظلم تو سیه ی روزی [EOS] [BOM]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Function to tokenize input text and truncate to block size\n",
        "def tokenize_and_truncate_text(text, block_size):\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
        "    if len(tokens) > block_size:\n",
        "        tokens = tokens[-block_size:]  # Truncate to the last block_size tokens\n",
        "    return torch.tensor(tokens, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Function to decode output tokens\n",
        "def decode_output(predicted_ids):\n",
        "    predicted_tokens = predicted_ids.tolist()  # Convert tensor to list\n",
        "    predicted_text = tokenizer.decode(predicted_tokens)\n",
        "    return predicted_text\n",
        "\n",
        "# Function to get model output for a single input text\n",
        "def get_model_output(model, input_text, config, temperature=1.0, top_k=50):\n",
        "    model.eval()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Tokenize and truncate input text\n",
        "    input_ids = tokenize_and_truncate_text(input_text, config.block_size)\n",
        "    input_ids = input_ids.to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits, _ = model(input_ids)\n",
        "        logits = logits[:, -1, :] / temperature  # Apply temperature\n",
        "\n",
        "        # Top-k sampling\n",
        "        top_k_logits, top_k_indices = torch.topk(logits, k=top_k, dim=-1)\n",
        "        probs = F.softmax(top_k_logits, dim=-1)\n",
        "\n",
        "        # Sample from the distribution\n",
        "        chosen_idx = torch.multinomial(probs, num_samples=1)\n",
        "        predicted_token_id = top_k_indices[0, chosen_idx[0]]\n",
        "\n",
        "        # Decode the predicted token\n",
        "        predicted_text = decode_output(predicted_token_id)\n",
        "\n",
        "    return predicted_text\n",
        "\n",
        "# Function to validate the predicted text\n",
        "def is_valid_token(token):\n",
        "    # Implement your logic to check if the token is valid or not\n",
        "    # This can include checking for known invalid sequences, punctuation, etc.\n",
        "    invalid_sequences = ['ا ی']\n",
        "    return token not in invalid_sequences\n",
        "\n",
        "# Sample input text\n",
        "input_text = \"بنشین که با من هر نظر\"\n",
        "input_text = \"دست هر کودک ده ساله شهر، شاخه معرفتی است\"\n",
        "input_text = \"تو خوشگل ناز منی \"\n",
        "input_text = \"سلام سلام بچه ها\"\n",
        "input_text = \"یه توپ دارم قلقلیه\"\n",
        "input_text = \"دور است کاروان سحر\"\n",
        "input_text = \"توانا بود هر که دانا بود\"\n",
        "input_text = \"حکیمان پیشین چنین گفته اند\"\n",
        "input_text = \"مرغ سحر\"\n",
        "\n",
        "\n",
        "# Define maximum BOM count\n",
        "max_bom_count = 20\n",
        "\n",
        "# Accumulate the complete generated text\n",
        "complete_text = input_text\n",
        "\n",
        "# Track the last few generated tokens\n",
        "repetition_threshold = 5\n",
        "last_few_tokens = []\n",
        "temperature = 0.7\n",
        "\n",
        "# Generate text in a loop until the maximum BOM count is reached\n",
        "bom_count = 0\n",
        "\n",
        "while bom_count < max_bom_count:\n",
        "    predicted_text = get_model_output(model, input_text, config, temperature=0.7, top_k=50)\n",
        "\n",
        "    # Prevent repeating sequences and filter invalid tokens\n",
        "    #if predicted_text.strip() in last_few_tokens or not is_valid_token(predicted_text.strip()):\n",
        "    #    temperature *= 1.1  # Increase temperature to promote diversity\n",
        "    #    predicted_text = get_model_output(model, input_text, config, temperature=temperature, top_k=50)\n",
        "    #else:\n",
        "    #    temperature = max(0.7, temperature * 0.95)  # Gradually decrease temperature back to a minimum\n",
        "\n",
        "    complete_text += ' ' + predicted_text.strip()  # Ensure proper spacing\n",
        "    last_few_tokens.append(predicted_text.strip())\n",
        "\n",
        "    if len(last_few_tokens) > repetition_threshold:\n",
        "        last_few_tokens.pop(0)\n",
        "\n",
        "    # Truncate the input text if it exceeds the block size\n",
        "    input_text += ' ' + predicted_text.strip()\n",
        "    input_ids = tokenize_and_truncate_text(input_text, config.block_size)\n",
        "    input_text = tokenizer.decode(input_ids[0].tolist())  # Update input_text to truncated version\n",
        "\n",
        "    # Add a new line after [EOS]\n",
        "    if '[EOS]' and '[BOM]' in predicted_text:\n",
        "        complete_text += '\\n'\n",
        "        bom_count += 1\n",
        "\n",
        "# Print the whole output after the loop\n",
        "print(f\"Predicted Text:\\n{complete_text}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(max(train_ids), max(val_ids)) + 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l35_PBiWtjOZ",
        "outputId": "e19a7bc6-2654-49b2-f846-e63c7fc2df29"
      },
      "id": "l35_PBiWtjOZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24899"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cfc515a8f59d4fc382326e12229bad83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fe20223a16f43bb9596ad985315c4f4",
              "IPY_MODEL_4ebf9a19837345198314ccedc05e95fd",
              "IPY_MODEL_e22055a2213d473580570f335294b651"
            ],
            "layout": "IPY_MODEL_be45d82c3513446783ca413417fdfa31"
          }
        },
        "6fe20223a16f43bb9596ad985315c4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaa82e85d8b84f39805001040e26bf97",
            "placeholder": "​",
            "style": "IPY_MODEL_806bbe76849248d48434bdc293627780",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4ebf9a19837345198314ccedc05e95fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3b10dc13699437fad10898105dd6ecc",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db460f022ff344c8a27f04d1e1fb3fce",
            "value": 350
          }
        },
        "e22055a2213d473580570f335294b651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec0face07da34ffb995c34faf96148d5",
            "placeholder": "​",
            "style": "IPY_MODEL_1174aafaee5f4f33a3d1b09970044b57",
            "value": " 350/350 [00:00&lt;00:00, 30.2kB/s]"
          }
        },
        "be45d82c3513446783ca413417fdfa31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa82e85d8b84f39805001040e26bf97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806bbe76849248d48434bdc293627780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3b10dc13699437fad10898105dd6ecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db460f022ff344c8a27f04d1e1fb3fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec0face07da34ffb995c34faf96148d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1174aafaee5f4f33a3d1b09970044b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5a9c1f666a647a9b84b115116ee5c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_658ad4bcfdb5416ab011a7280ba6e52d",
              "IPY_MODEL_d47dc3fbdc1a464399e4b6ba4b53fa4a",
              "IPY_MODEL_84d9b45abc8d4a52a3b55d1a634a8e5f"
            ],
            "layout": "IPY_MODEL_6bb54a0ce43043e892fd78c1c1bccb2d"
          }
        },
        "658ad4bcfdb5416ab011a7280ba6e52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbcda56347ab4d57ac20f763091da5da",
            "placeholder": "​",
            "style": "IPY_MODEL_a6256014ae88439ca75293cc345ddcbe",
            "value": "config.json: 100%"
          }
        },
        "d47dc3fbdc1a464399e4b6ba4b53fa4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08034eaca41346c984203d9372946955",
            "max": 1331,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9451733032542658f07aa90417968d2",
            "value": 1331
          }
        },
        "84d9b45abc8d4a52a3b55d1a634a8e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a7da95489c14578a24e6cf956d720f4",
            "placeholder": "​",
            "style": "IPY_MODEL_f95323e68cd7468fbe94b29dfb13d90c",
            "value": " 1.33k/1.33k [00:00&lt;00:00, 120kB/s]"
          }
        },
        "6bb54a0ce43043e892fd78c1c1bccb2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcda56347ab4d57ac20f763091da5da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6256014ae88439ca75293cc345ddcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08034eaca41346c984203d9372946955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9451733032542658f07aa90417968d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a7da95489c14578a24e6cf956d720f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f95323e68cd7468fbe94b29dfb13d90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26b2757b11004fc3b74e96ebbccc1ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_081a32d5dfd54c3a860899093e789a7d",
              "IPY_MODEL_81f1cbf854da4fb591233a7d2a71bd8b",
              "IPY_MODEL_c2233d53b9084ab8a1e33ff02430d38e"
            ],
            "layout": "IPY_MODEL_76e1674758ac4c45b0c319492d1eef3c"
          }
        },
        "081a32d5dfd54c3a860899093e789a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49bfe95de3344d0e910e94c34100446b",
            "placeholder": "​",
            "style": "IPY_MODEL_6bfef887d4864bbe99e8950a77da5151",
            "value": "spiece.model: 100%"
          }
        },
        "81f1cbf854da4fb591233a7d2a71bd8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e8df18c74074262a388e5c69d7b31c8",
            "max": 537052,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ced7135ecdfc4206929b004dacfa5d78",
            "value": 537052
          }
        },
        "c2233d53b9084ab8a1e33ff02430d38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f0482bfbb3c45bcb9f8bf23f0ad82a1",
            "placeholder": "​",
            "style": "IPY_MODEL_12c5dc9a501647b992ea5f3f63408fdb",
            "value": " 537k/537k [00:00&lt;00:00, 4.12MB/s]"
          }
        },
        "76e1674758ac4c45b0c319492d1eef3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49bfe95de3344d0e910e94c34100446b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bfef887d4864bbe99e8950a77da5151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e8df18c74074262a388e5c69d7b31c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced7135ecdfc4206929b004dacfa5d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f0482bfbb3c45bcb9f8bf23f0ad82a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c5dc9a501647b992ea5f3f63408fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cb4368797ae4032829325edc1e6c8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ba9eada88d54ba2ab7c4eadabc8006f",
              "IPY_MODEL_eb8328e1eecb4bf59a26fb6e2abe2049",
              "IPY_MODEL_c722b112780942d1b09c2b8e8252a2fa"
            ],
            "layout": "IPY_MODEL_28b421b4bbe14c7688b782296284efa7"
          }
        },
        "8ba9eada88d54ba2ab7c4eadabc8006f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aaeefa03b5e42c983af877923044e0b",
            "placeholder": "​",
            "style": "IPY_MODEL_4e4e90660cdf45aa8dc7fa8aa2ae4597",
            "value": "tokenizer.json: 100%"
          }
        },
        "eb8328e1eecb4bf59a26fb6e2abe2049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7523f96d578844a78a86a83c6acb4191",
            "max": 1127358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1c79e7f0e28448098a20cf5df50b430",
            "value": 1127358
          }
        },
        "c722b112780942d1b09c2b8e8252a2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_193301b07794490786b2a0402ce7cae5",
            "placeholder": "​",
            "style": "IPY_MODEL_ea8b8d7b74bb4bef9a5f1ad85fa6e8d7",
            "value": " 1.13M/1.13M [00:00&lt;00:00, 8.15MB/s]"
          }
        },
        "28b421b4bbe14c7688b782296284efa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aaeefa03b5e42c983af877923044e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e4e90660cdf45aa8dc7fa8aa2ae4597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7523f96d578844a78a86a83c6acb4191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c79e7f0e28448098a20cf5df50b430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "193301b07794490786b2a0402ce7cae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea8b8d7b74bb4bef9a5f1ad85fa6e8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0611c00bf1e44d8b1e8a08ee894d430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f33e5b822b774b1b8ebdfedfef9bafb6",
              "IPY_MODEL_75a69bb7c61147c895623c69d7835436",
              "IPY_MODEL_6f7183a2025d4c86a0cbd234d4eeed00"
            ],
            "layout": "IPY_MODEL_4c349d4d2bf6438697d371c2098a2d95"
          }
        },
        "f33e5b822b774b1b8ebdfedfef9bafb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_204d92e96c2e4c9a84e4ac34cf9894b4",
            "placeholder": "​",
            "style": "IPY_MODEL_f85e4637940f4bd3acb1257c5bf1a17b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "75a69bb7c61147c895623c69d7835436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6ac0a325dad4bccadccb2458bdc6479",
            "max": 399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eaff2a4f15a341c3af40198d887301d8",
            "value": 399
          }
        },
        "6f7183a2025d4c86a0cbd234d4eeed00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b7e2ab5cb474aef8c31c4e6980003cd",
            "placeholder": "​",
            "style": "IPY_MODEL_5bac0e89fe6040d7a2dc0205eac30a19",
            "value": " 399/399 [00:00&lt;00:00, 24.3kB/s]"
          }
        },
        "4c349d4d2bf6438697d371c2098a2d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "204d92e96c2e4c9a84e4ac34cf9894b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f85e4637940f4bd3acb1257c5bf1a17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6ac0a325dad4bccadccb2458bdc6479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaff2a4f15a341c3af40198d887301d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b7e2ab5cb474aef8c31c4e6980003cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bac0e89fe6040d7a2dc0205eac30a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}